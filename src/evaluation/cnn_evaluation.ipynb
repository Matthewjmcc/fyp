{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5604aa68-cdae-4f79-97d3-34e182a0ca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, tensorflow as tf\n",
    "import sys, time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dropout, MaxPooling1D, GlobalAveragePooling1D, Conv1DTranspose, LSTM, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137720cc-886d-4641-9490-0bf697082df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - ss_res/(ss_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "414b045b-f57d-495c-beb8-b710c55370dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_train, base_data_test = np.load('../../data/training_data/training_data_1month.npy', allow_pickle=True)\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e3ed8d-a134-4ffb-94de-6e79786ca695",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2> Scale Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90635f26-def5-40d8-a820-3150b41f9a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 730, 4) (108, 730, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "base_data_train, base_data_test = np.load('../../data/training_data/training_data_1month.npy', allow_pickle=True)\n",
    "scalers = {var_name: MinMaxScaler(feature_range=(-1,1)) for var_name in ['G.air.T', 'G.E_th_I', 'G.sky.T', 'G.E_el_I']}\n",
    "\n",
    "air_var, sky_var, el_var, th_var = base_data_train[:,:,0], base_data_train[:,:,1], base_data_train[:,:,2], base_data_train[:,:,3]\n",
    "air_var_test, sky_var_test, el_var_test, th_var_test = base_data_test[:,:,0], base_data_test[:,:,1], base_data_test[:,:,2], base_data_test[:,:,3]\n",
    "\n",
    "scaled_data_train = np.stack((scalers['G.air.T'].fit_transform(air_var),\n",
    "                             scalers['G.sky.T'].fit_transform(sky_var),\n",
    "                             scalers['G.E_el_I'].fit_transform(el_var),\n",
    "                             scalers['G.E_th_I'].fit_transform(th_var)), axis=-1)\n",
    "scaled_data_test = np.stack((scalers['G.air.T'].fit_transform(air_var),\n",
    "                             scalers['G.sky.T'].fit_transform(sky_var),\n",
    "                             scalers['G.E_el_I'].fit_transform(el_var),\n",
    "                             scalers['G.E_th_I'].fit_transform(th_var)), axis=-1)\n",
    "print(scaled_data_train.shape, scaled_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be189d7-6067-4652-8dc0-f688acece12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 730, 2) (12, 730, 2) (108, 730, 2) (12, 730, 2)\n"
     ]
    }
   ],
   "source": [
    "def split_base_data(base_data_train, base_data_test, th_indices=[0, 3], el_indices=[1, 2]):\n",
    "    th_base_data_train, th_base_data_test = base_data_train[:, :, th_indices], base_data_test[:, :, th_indices]\n",
    "    el_base_data_train, el_base_data_test = base_data_train[:, :, el_indices], base_data_test[:, :, el_indices]\n",
    "    return th_base_data_train, th_base_data_test, el_base_data_train, el_base_data_test\n",
    "\n",
    "th_base_data_train, th_base_data_test, el_base_data_train, el_base_data_test = split_base_data(base_data_train, base_data_test)\n",
    "print(th_base_data_train.shape, th_base_data_test.shape, el_base_data_train.shape, el_base_data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff891f3-88f4-4fec-95fb-c99b90a73ace",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2> CNN Models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a190fe07-f580-4d55-9daf-dbcbe79b8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=24, activation='relu', input_shape=(input_shape)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Conv1D(filters=64, kernel_size=24, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(730, activation='linear')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a72256e-8e9d-4013-90ce-1b4cae833dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn(training_data, th_or_el):\n",
    "    X_train = training_data[:,:,0].reshape(-1,730,1)\n",
    "    y_train = training_data[:,:,1]\n",
    "\n",
    "    if th_or_el == 0:\n",
    "        X_test = scaled_data_test[:,:,0].reshape(-1, 730, 1)  \n",
    "        y_test = scaled_data_test[:,:,3]\n",
    "    else:\n",
    "        X_test = scaled_data_test[:,:,1].reshape(-1, 730, 1)  \n",
    "        y_test = scaled_data_test[:,:,2]\n",
    "\n",
    "    X_train, X_train_val, y_train, y_train_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)\n",
    "                                                                  \n",
    "    model = create_cnn((X_train.shape[1], X_train.shape[2]))\n",
    "    model.compile(optimizer=Adam(), loss='mse', metrics=['mse', 'mae'])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='mse', patience=10, verbose=1, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='mse', factor=0.5, patience=5, verbose=1)\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=16, callbacks=[early_stopping, reduce_lr], verbose=0, validation_data=(X_train_val, y_train_val))\n",
    "\n",
    "    loss, mse, mae = model.evaluate(X_test, y_test)\n",
    "    r2 = r_squared(tf.convert_to_tensor(y_test, dtype=tf.float32), tf.convert_to_tensor(model.predict(X_test), dtype=tf.float32))\n",
    "    \n",
    "    return {'mse':mse, 'mae':mae, 'r2':r2.numpy()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc6be8c1-0a57-414d-8461-866b41a76655",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reps = 10\n",
    "\n",
    "def test_cnn_wrapper(data, th_or_el=0):\n",
    "    mse, mae, r2 = 0, 0, 0\n",
    "\n",
    "    # Run each CNN training 10 times to ensure results are significant and not outliers\n",
    "    for i in range(num_reps):\n",
    "        print(f'RUN: {i}')\n",
    "        results = test_cnn(np.random.permutation(data), th_or_el) # permuting the data for each run just to ensure full shuffling\n",
    "        mse += results['mse']\n",
    "        mae += results['mae']\n",
    "        r2  += results['r2']\n",
    "\n",
    "    return {'mse':mse/num_reps, 'mae':mae/num_reps, 'r2':r2/num_reps}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa06e5-c9b5-461f-bc7a-98375e2994e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a02e7804-5dee-469e-881c-6d0f2648e6d5",
   "metadata": {},
   "source": [
    "<h2> Load data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "763f646c-f6c2-45e3-bb6c-f2ce3b45bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_path, context, dataset_names):\n",
    "    datasets = {}\n",
    "    for name in dataset_names:\n",
    "        file_path = f'{base_path}/{context}_{name}_generated_samples.npy'\n",
    "        datasets[name] = np.load(file_path, allow_pickle=True)\n",
    "    return datasets\n",
    "\n",
    "base_path_vae = '../../data/vae_synthetic_data/'\n",
    "base_path_gan = '../../data/gan_synthetic_data/'\n",
    "th_context = 'th_v_air'\n",
    "el_context = 'el_v_sky'\n",
    "\n",
    "th_vae_datasets = ['b20l5', 'b4l10', 'b16l10', 'b8l20', 'b4l5', 'b16l5', 'b20l3', 'b24l15', 'b8l15', 'b24l50']\n",
    "th_gan_datasets = ['b6e100', 'b8e500']#['b32e500', 'b8e1000', 'b20e100', 'b32e100', 'b6e100', 'b8e500']\n",
    "\n",
    "th_vae_data = load_data(base_path_vae, th_context, th_vae_datasets)\n",
    "th_gan_data = load_data(base_path_gan, th_context, th_gan_datasets)\n",
    "\n",
    "el_vae_datasets = []\n",
    "el_gan_datasets = ['b4e1000','b6e100','b8e500','b8e1000', 'b10e100', 'b12e100', 'b12e500', 'b16e500', 'b20e500', 'b24e1000', 'b32e1000']\n",
    "\n",
    "#\n",
    "el_gan_data = load_data(base_path_gan, el_context, el_gan_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a44b057e-c56d-426e-a61a-0fc5c5d6706a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [(1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2)]\n",
      "2 [(1000, 730, 2), (1000, 730, 2)]\n",
      "11 [(1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(len(th_vae_data), [th_vae_data[th_vae_datasets[i]].shape for i in range(len(th_vae_data))])\n",
    "print(len(th_gan_data), [th_gan_data[th_gan_datasets[i]].shape for i in range(len(th_gan_data))])\n",
    "\n",
    "print(len(el_gan_data), [el_gan_data[el_gan_datasets[i]].shape for i in range(len(el_gan_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f6341-ad77-404e-a731-5d672b788255",
   "metadata": {},
   "source": [
    "<h2> Train CNNs </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e32ba9-d65f-4a89-ab8a-d895cfc9a5cd",
   "metadata": {},
   "source": [
    "<h3> Ground Truth Datasets </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3414deb-dd19-47d4-82b9-c03f4137584a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0998 - mse: 0.0998 - mae: 0.2326\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0925 - mse: 0.0925 - mae: 0.2185\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0962 - mse: 0.0962 - mae: 0.2239\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1058 - mse: 0.1058 - mae: 0.2503\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0910 - mse: 0.0910 - mae: 0.2217\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1006 - mse: 0.1006 - mae: 0.2295\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0959 - mse: 0.0959 - mae: 0.2294\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0993 - mse: 0.0993 - mae: 0.2345\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1027 - mse: 0.1027 - mae: 0.2458\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0957 - mse: 0.0957 - mae: 0.2229\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2835 - mse: 0.2835 - mae: 0.4055\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3188 - mse: 0.3188 - mae: 0.4337\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3169 - mse: 0.3169 - mae: 0.4313\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2680 - mse: 0.2680 - mae: 0.3917\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3158 - mse: 0.3158 - mae: 0.4312\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2882 - mse: 0.2882 - mae: 0.4078\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2787 - mse: 0.2787 - mae: 0.4010\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2508 - mse: 0.2508 - mae: 0.3770\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2808 - mse: 0.2808 - mae: 0.4054\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2924 - mse: 0.2924 - mae: 0.4167\n",
      "4/4 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(test_cnn_wrapper(scaled_data_train[:,:,[0,3]], 0), index=[0]).to_csv('../../data/evaluation_results/th_gt.csv')\n",
    "pd.DataFrame(test_cnn_wrapper(scaled_data_train[:,:,[1,2]], 1), index=[0]).to_csv('../../data/evaluation_results/el_gt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c34e06-8cec-455c-9750-c3dedae82445",
   "metadata": {},
   "source": [
    "<h3> Synthetic Datasets </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47ab1da6-24d3-494d-b94b-6d5b9834e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_cnn(data_dicts, model_type, column_index, base_path='../../data/evaluation_results/'):\n",
    "    for dataset_name, dataset in data_dicts.items():\n",
    "        cnn_test_results = test_cnn_wrapper(dataset[0:216, :, :], column_index)\n",
    "\n",
    "        result_df = pd.DataFrame(cnn_test_results, index=[0])\n",
    "        result_file_name = f'{base_path}{model_type}_{\"th\" if column_index==0 else \"el\"}_{dataset_name}.csv'\n",
    "        result_df.to_csv(result_file_name)\n",
    "        print(f'CNN results for {dataset_name}: {result_df}')\n",
    "        print(f'Saved CNN evaluation results for {dataset_name} to: {result_file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f7849-ccd0-4196-9af6-87c4a1edba3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6127 - mse: 0.6127 - mae: 0.6989\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6120 - mse: 0.6120 - mae: 0.6897\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6470 - mse: 0.6470 - mae: 0.7373\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6420 - mse: 0.6420 - mae: 0.7226\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6281 - mse: 0.6281 - mae: 0.7148\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6170 - mse: 0.6170 - mae: 0.6968\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6772 - mse: 0.6772 - mae: 0.6989\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6174 - mse: 0.6174 - mae: 0.6887\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6207 - mse: 0.6207 - mae: 0.7056\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6268 - mse: 0.6268 - mae: 0.6993\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "CNN results for b4e1000:         mse       mae        r2\n",
      "0  0.630071  0.705254  0.097189\n",
      "Saved CNN evaluation results for b4e1000 to: ../../data/evaluation_results/gan_el_b4e1000.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7673 - mse: 0.7673 - mae: 0.8360\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7707 - mse: 0.7707 - mae: 0.8381\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7779 - mse: 0.7779 - mae: 0.8464\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7754 - mse: 0.7754 - mae: 0.8452\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7789 - mse: 0.7789 - mae: 0.8438\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7681 - mse: 0.7681 - mae: 0.8375\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7890 - mse: 0.7890 - mae: 0.8516\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7715 - mse: 0.7715 - mae: 0.8414\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7762 - mse: 0.7762 - mae: 0.8462\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7734 - mse: 0.7734 - mae: 0.8429\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "CNN results for b6e100:         mse       mae        r2\n",
      "0  0.774832  0.842921 -0.110235\n",
      "Saved CNN evaluation results for b6e100 to: ../../data/evaluation_results/gan_el_b6e100.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7673 - mse: 0.7673 - mae: 0.8297\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7890 - mse: 0.7890 - mae: 0.8283\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7699 - mse: 0.7699 - mae: 0.8109\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7803 - mse: 0.7803 - mae: 0.8225\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7664 - mse: 0.7664 - mae: 0.8177\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7723 - mse: 0.7723 - mae: 0.8174\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7545 - mse: 0.7545 - mae: 0.8003\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7823 - mse: 0.7823 - mae: 0.8368\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7646 - mse: 0.7646 - mae: 0.8192\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7920 - mse: 0.7920 - mae: 0.8281\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "CNN results for b8e500:         mse       mae       r2\n",
      "0  0.773865  0.821096 -0.10885\n",
      "Saved CNN evaluation results for b8e500 to: ../../data/evaluation_results/gan_el_b8e500.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7142 - mse: 0.7142 - mae: 0.7641\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7524 - mse: 0.7524 - mae: 0.7663\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7558 - mse: 0.7558 - mae: 0.7665\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7607 - mse: 0.7607 - mae: 0.7835\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "RUN: 4\n"
     ]
    }
   ],
   "source": [
    "#evaluate_and_save_cnn(th_vae_data, 'vae', 0)\n",
    "#evaluate_and_save_cnn(th_gan_data, 'gan', 0)\n",
    "\n",
    "evaluate_and_save_cnn(el_gan_data, 'gan', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd17245-1de8-4296-9897-7e3afefef58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_and_save_cnn(el_vae_data, 'vae', 1)\n",
    "#evaluate_and_save_cnn(el_gan_data, 'gan', 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a037f92-ded3-42b4-aefc-306d635935c0",
   "metadata": {},
   "source": [
    "<h3> Blended Datasets </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f99b5a33-68f9-415e-82c3-42ff685781ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_cnn_blended(data_dicts, model_type, column_index, base_path='../../data/evaluation_results/'):\n",
    "    for dataset_name, dataset in data_dicts.items():\n",
    "        scaled_data = scaled_data_train[:,:,[0,3]] if column_index==0 else scaled_data_train[:,:,[1,2]]\n",
    "        cnn_test_results = test_cnn_wrapper(np.concatenate((scaled_data, dataset[0:216,:,:]), column_index))\n",
    "\n",
    "        result_df = pd.DataFrame(cnn_test_results, index=[0])\n",
    "        result_file_name = f'{base_path}{model_type}_blended_{\"th\" if column_index==0 else \"el\"}_{dataset_name}.csv'\n",
    "        result_df.to_csv(result_file_name)\n",
    "        print(f'CNN results for {dataset_name}: {result_df}')\n",
    "        print(f'Saved CNN evaluation results for {dataset_name} to: {result_file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d90b4d32-80d8-4d5f-b767-7a26ab07af24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0975 - mse: 0.0975 - mae: 0.2271\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1203 - mse: 0.1203 - mae: 0.2530\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1066 - mse: 0.1066 - mae: 0.2342\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0975 - mse: 0.0975 - mae: 0.2310\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1050 - mse: 0.1050 - mae: 0.2313\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1096 - mse: 0.1096 - mae: 0.2442\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1011 - mse: 0.1011 - mae: 0.2244\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1066 - mse: 0.1066 - mae: 0.2379\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1111 - mse: 0.1111 - mae: 0.2494\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1101 - mse: 0.1101 - mae: 0.2408\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "CNN results for b20l5:         mse       mae        r2\n",
      "0  0.106543  0.237324  0.402039\n",
      "Saved CNN evaluation results for b20l5 to: ../../data/evaluation_results/vae_blended_th_b20l5.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0880 - mse: 0.0880 - mae: 0.2121\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0863 - mse: 0.0863 - mae: 0.2117\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0911 - mse: 0.0911 - mae: 0.2181\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0897 - mse: 0.0897 - mae: 0.2276\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0966 - mse: 0.0966 - mae: 0.2306\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0910 - mse: 0.0910 - mae: 0.2284\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1021 - mse: 0.1021 - mae: 0.2471\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1004 - mse: 0.1004 - mae: 0.2361\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0867 - mse: 0.0867 - mae: 0.2085\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0925 - mse: 0.0925 - mae: 0.2236\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "CNN results for b4l10:         mse       mae        r2\n",
      "0  0.092443  0.224371  0.481172\n",
      "Saved CNN evaluation results for b4l10 to: ../../data/evaluation_results/vae_blended_th_b4l10.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1228 - mse: 0.1228 - mae: 0.2569\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 97: early stopping\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1255 - mse: 0.1255 - mae: 0.2610\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1127 - mse: 0.1127 - mae: 0.2290\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1233 - mse: 0.1233 - mae: 0.2548\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1170 - mse: 0.1170 - mae: 0.2510\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1244 - mse: 0.1244 - mae: 0.2579\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1190 - mse: 0.1190 - mae: 0.2431\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1165 - mse: 0.1165 - mae: 0.2470\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 82: early stopping\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1220 - mse: 0.1220 - mae: 0.2526\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 94: early stopping\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1256 - mse: 0.1256 - mae: 0.2544\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "CNN results for b16l10:         mse       mae        r2\n",
      "0  0.120886  0.250776  0.321538\n",
      "Saved CNN evaluation results for b16l10 to: ../../data/evaluation_results/vae_blended_th_b16l10.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 72: early stopping\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1303 - mse: 0.1303 - mae: 0.2575\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 91: early stopping\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1277 - mse: 0.1277 - mae: 0.2604\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1305 - mse: 0.1305 - mae: 0.2603\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 83: early stopping\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1273 - mse: 0.1273 - mae: 0.2572\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1301 - mse: 0.1301 - mae: 0.2657\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 96: early stopping\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1541 - mse: 0.1541 - mae: 0.2980\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1457 - mse: 0.1457 - mae: 0.2774\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1397 - mse: 0.1397 - mae: 0.2722\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 98: early stopping\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1242 - mse: 0.1242 - mae: 0.2564\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1107 - mse: 0.1107 - mae: 0.2461\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "CNN results for b8l20:         mse       mae        r2\n",
      "0  0.132024  0.265103  0.259028\n",
      "Saved CNN evaluation results for b8l20 to: ../../data/evaluation_results/vae_blended_th_b8l20.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1010 - mse: 0.1010 - mae: 0.2334\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0883 - mse: 0.0883 - mae: 0.2156\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0956 - mse: 0.0956 - mae: 0.2196\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1034 - mse: 0.1034 - mae: 0.2432\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0927 - mse: 0.0927 - mae: 0.2219\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1029 - mse: 0.1029 - mae: 0.2308\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0902 - mse: 0.0902 - mae: 0.2182\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0960 - mse: 0.0960 - mae: 0.2244\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1045 - mse: 0.1045 - mae: 0.2373\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0935 - mse: 0.0935 - mae: 0.2230\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "CNN results for b4l5:         mse       mae        r2\n",
      "0  0.096816  0.226748  0.456629\n",
      "Saved CNN evaluation results for b4l5 to: ../../data/evaluation_results/vae_blended_th_b4l5.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1029 - mse: 0.1029 - mae: 0.2380\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1035 - mse: 0.1035 - mae: 0.2440\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1032 - mse: 0.1032 - mae: 0.2342\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1067 - mse: 0.1067 - mae: 0.2348\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1093 - mse: 0.1093 - mae: 0.2399\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0983 - mse: 0.0983 - mae: 0.2356\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0981 - mse: 0.0981 - mae: 0.2246\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0948 - mse: 0.0948 - mae: 0.2271\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1075 - mse: 0.1075 - mae: 0.2428\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0921 - mse: 0.0921 - mae: 0.2169\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "CNN results for b16l5:         mse       mae       r2\n",
      "0  0.101641  0.233782  0.42955\n",
      "Saved CNN evaluation results for b16l5 to: ../../data/evaluation_results/vae_blended_th_b16l5.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0821 - mse: 0.0821 - mae: 0.2105\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0820 - mse: 0.0820 - mae: 0.2063\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0825 - mse: 0.0825 - mae: 0.2108\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0727 - mse: 0.0727 - mae: 0.1967\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0716 - mse: 0.0716 - mae: 0.1938\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0760 - mse: 0.0760 - mae: 0.1945\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0744 - mse: 0.0744 - mae: 0.1975\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0819 - mse: 0.0819 - mae: 0.2111\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0750 - mse: 0.0750 - mae: 0.1965\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0830 - mse: 0.0830 - mae: 0.2192\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "CNN results for b20l3:         mse       mae        r2\n",
      "0  0.078115  0.203689  0.561587\n",
      "Saved CNN evaluation results for b20l3 to: ../../data/evaluation_results/vae_blended_th_b20l3.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1021 - mse: 0.1021 - mae: 0.2440\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0922 - mse: 0.0922 - mae: 0.2197\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0927 - mse: 0.0927 - mae: 0.2244\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0888 - mse: 0.0888 - mae: 0.2225\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0980 - mse: 0.0980 - mae: 0.2327\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0895 - mse: 0.0895 - mae: 0.2254\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1029 - mse: 0.1029 - mae: 0.2362\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1070 - mse: 0.1070 - mae: 0.2403\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0959 - mse: 0.0959 - mae: 0.2240\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1075 - mse: 0.1075 - mae: 0.2426\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "CNN results for b24l15:         mse       mae        r2\n",
      "0  0.097664  0.231185  0.451871\n",
      "Saved CNN evaluation results for b24l15 to: ../../data/evaluation_results/vae_blended_th_b24l15.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0983 - mse: 0.0983 - mae: 0.2307\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1008 - mse: 0.1008 - mae: 0.2261\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0848 - mse: 0.0848 - mae: 0.2049\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0838 - mse: 0.0838 - mae: 0.2029\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0906 - mse: 0.0906 - mae: 0.2167\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1014 - mse: 0.1014 - mae: 0.2330\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0926 - mse: 0.0926 - mae: 0.2216\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0890 - mse: 0.0890 - mae: 0.2240\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0984 - mse: 0.0984 - mae: 0.2347\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0927 - mse: 0.0927 - mae: 0.2258\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "CNN results for b8l15:         mse       mae        r2\n",
      "0  0.093242  0.222046  0.476691\n",
      "Saved CNN evaluation results for b8l15 to: ../../data/evaluation_results/vae_blended_th_b8l15.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 96: early stopping\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1132 - mse: 0.1132 - mae: 0.2378\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1070 - mse: 0.1070 - mae: 0.2349\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 87.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 97: early stopping\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1049 - mse: 0.1049 - mae: 0.2336\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1063 - mse: 0.1063 - mae: 0.2329\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 69: early stopping\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1182 - mse: 0.1182 - mae: 0.2484\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 94: early stopping\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1100 - mse: 0.1100 - mae: 0.2352\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 71: early stopping\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1115 - mse: 0.1115 - mae: 0.2376\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 100: early stopping\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1077 - mse: 0.1077 - mae: 0.2330\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 94: early stopping\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1049 - mse: 0.1049 - mae: 0.2322\n",
      "4/4 [==============================] - 0s 18ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1065 - mse: 0.1065 - mae: 0.2279\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "CNN results for b24l50:         mse       mae        r2\n",
      "0  0.109022  0.235341  0.388126\n",
      "Saved CNN evaluation results for b24l50 to: ../../data/evaluation_results/vae_blended_th_b24l50.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1047 - mse: 0.1047 - mae: 0.2387\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1062 - mse: 0.1062 - mae: 0.2420\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1009 - mse: 0.1009 - mae: 0.2229\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0973 - mse: 0.0973 - mae: 0.2256\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1016 - mse: 0.1016 - mae: 0.2326\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1049 - mse: 0.1049 - mae: 0.2379\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1036 - mse: 0.1036 - mae: 0.2443\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0934 - mse: 0.0934 - mae: 0.2194\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0925 - mse: 0.0925 - mae: 0.2092\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1058 - mse: 0.1058 - mae: 0.2549\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "CNN results for b32e500:         mse       mae        r2\n",
      "0  0.101084  0.232737  0.432675\n",
      "Saved CNN evaluation results for b32e500 to: ../../data/evaluation_results/gan_blended_th_b32e500.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0991 - mse: 0.0991 - mae: 0.2281\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1002 - mse: 0.1002 - mae: 0.2272\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0970 - mse: 0.0970 - mae: 0.2278\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1021 - mse: 0.1021 - mae: 0.2409\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1047 - mse: 0.1047 - mae: 0.2328\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1065 - mse: 0.1065 - mae: 0.2390\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1020 - mse: 0.1020 - mae: 0.2246\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1063 - mse: 0.1063 - mae: 0.2386\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1061 - mse: 0.1061 - mae: 0.2324\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1051 - mse: 0.1051 - mae: 0.2397\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "CNN results for b8e1000:         mse       mae        r2\n",
      "0  0.102926  0.233114  0.422341\n",
      "Saved CNN evaluation results for b8e1000 to: ../../data/evaluation_results/gan_blended_th_b8e1000.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0857 - mse: 0.0857 - mae: 0.2099\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0884 - mse: 0.0884 - mae: 0.2143\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0776 - mse: 0.0776 - mae: 0.2039\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0947 - mse: 0.0947 - mae: 0.2175\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2127\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0763 - mse: 0.0763 - mae: 0.2022\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1023 - mse: 0.1023 - mae: 0.2259\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0958 - mse: 0.0958 - mae: 0.2240\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0912 - mse: 0.0912 - mae: 0.2167\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0965 - mse: 0.0965 - mae: 0.2269\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "CNN results for b20e100:         mse       mae        r2\n",
      "0  0.089572  0.215405  0.497288\n",
      "Saved CNN evaluation results for b20e100 to: ../../data/evaluation_results/gan_blended_th_b20e100.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 67: early stopping\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1201 - mse: 0.1201 - mae: 0.2524\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 89: early stopping\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1267 - mse: 0.1267 - mae: 0.2601\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "Epoch 100: early stopping\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1134 - mse: 0.1134 - mae: 0.2408\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 90: early stopping\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1296 - mse: 0.1296 - mae: 0.2611\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 60: early stopping\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1241 - mse: 0.1241 - mae: 0.2512\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 61: early stopping\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1245 - mse: 0.1245 - mae: 0.2554\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 84: early stopping\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1238 - mse: 0.1238 - mae: 0.2569\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 51: early stopping\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1313 - mse: 0.1313 - mae: 0.2778\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 58: early stopping\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1272 - mse: 0.1272 - mae: 0.2598\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 82: early stopping\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1613 - mse: 0.1613 - mae: 0.3029\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "CNN results for b32e100:         mse       mae        r2\n",
      "0  0.128197  0.261819  0.280506\n",
      "Saved CNN evaluation results for b32e100 to: ../../data/evaluation_results/gan_blended_th_b32e100.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0842 - mse: 0.0842 - mae: 0.2100\n",
      "4/4 [==============================] - 0s 11ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0818 - mse: 0.0818 - mae: 0.2028\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0835 - mse: 0.0835 - mae: 0.2173\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0902 - mse: 0.0902 - mae: 0.2166\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0911 - mse: 0.0911 - mae: 0.2165\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0977 - mse: 0.0977 - mae: 0.2212\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.58 MiB for an array with shape (10560, 64) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m evaluate_and_save_cnn_blended(th_vae_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvae\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mevaluate_and_save_cnn_blended\u001b[49m\u001b[43m(\u001b[49m\u001b[43mth_gan_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#evaluate_and_save_cnn_blended(el_vae_data, 'vae', 1)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#evaluate_and_save_cnn_blended(el_gan_data, 'gan', 1)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[64], line 4\u001b[0m, in \u001b[0;36mevaluate_and_save_cnn_blended\u001b[1;34m(data_dicts, model_type, column_index, base_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name, dataset \u001b[38;5;129;01min\u001b[39;00m data_dicts\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m     scaled_data \u001b[38;5;241m=\u001b[39m scaled_data_train[:,:,[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m]] \u001b[38;5;28;01mif\u001b[39;00m column_index\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scaled_data_train[:,:,[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]]\n\u001b[1;32m----> 4\u001b[0m     cnn_test_results \u001b[38;5;241m=\u001b[39m \u001b[43mtest_cnn_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m216\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(cnn_test_results, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      7\u001b[0m     result_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_blended_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mth\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m column_index\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[1;32mIn[57], line 9\u001b[0m, in \u001b[0;36mtest_cnn_wrapper\u001b[1;34m(data, th_or_el)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_reps):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRUN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mtest_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermutation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth_or_el\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# permuting the data for each run just to ensure full shuffling\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     mse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m     mae \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[56], line 19\u001b[0m, in \u001b[0;36mtest_cnn\u001b[1;34m(training_data, th_or_el)\u001b[0m\n\u001b[0;32m     17\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m loss, mse, mae \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[0;32m     22\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r_squared(tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(y_test, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32), tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(model\u001b[38;5;241m.\u001b[39mpredict(X_test), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:4248\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   4236\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the value of more than one tensor variable.\u001b[39;00m\n\u001b[0;32m   4237\u001b[0m \n\u001b[0;32m   4238\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4245\u001b[0m \u001b[38;5;124;03m    RuntimeError: If this method is called inside defun.\u001b[39;00m\n\u001b[0;32m   4246\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 4248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tensors]\n\u001b[0;32m   4249\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m   4250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get value inside Tensorflow graph function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.58 MiB for an array with shape (10560, 64) and data type float32"
     ]
    }
   ],
   "source": [
    "evaluate_and_save_cnn_blended(th_vae_data, 'vae', 0)\n",
    "evaluate_and_save_cnn_blended(th_gan_data, 'gan', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12066c1-16c7-4313-8c7e-04229b7a4910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_and_save_cnn_blended(el_vae_data, 'vae', 1)\n",
    "#evaluate_and_save_cnn_blended(el_gan_data, 'gan', 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919799d-e034-4e82-8459-28975d0b2fba",
   "metadata": {},
   "source": [
    "<h2> Select and compare data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30a3d709-1516-4d53-970b-5048df5adff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'../../data/evaluation_results\\\\vae_blended_th_b16l10.csv': 0    0.120886\n",
      "Name: mse, dtype: float64, '../../data/evaluation_results\\\\vae_blended_th_b16l5.csv': 0    0.101641\n",
      "Name: mse, dtype: float64, '../../data/evaluation_results\\\\vae_blended_th_b20l3.csv': 0    0.078115\n",
      "Name: mse, dtype: float64, '../../data/evaluation_results\\\\vae_blended_th_b20l5.csv': 0    0.106543\n",
      "Name: mse, dtype: float64, '../../data/evaluation_results\\\\vae_blended_th_b24l15.csv': 0    0.097664\n",
      "Name: mse, dtype: float64, '../../data/evaluation_results\\\\vae_blended_th_b24l50.csv': 0    0.109022\n",
      "Name: mse, dtype: float64, '../../data/evaluation_results\\\\vae_blended_th_b4l10.csv': 0    0.092443\n",
      "Name: mse, dtype: float64, '../../data/evaluation_results\\\\vae_blended_th_b4l5.csv': 0    0.096816\n",
      "Name: mse, dtype: float64, '../../data/evaluation_results\\\\vae_blended_th_b8l15.csv': 0    0.093242\n",
      "Name: mse, dtype: float64, '../../data/evaluation_results\\\\vae_blended_th_b8l20.csv': 0    0.132024\n",
      "Name: mse, dtype: float64}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "folder_path = '../../data/evaluation_results/'\n",
    "prefix = 'vae_blended_th'\n",
    "\n",
    "file_paths = glob.glob(f'{folder_path}{prefix}*.csv')\n",
    "\n",
    "mse_vals = {}\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    mse_vals[file_path] = df['mse']\n",
    "\n",
    "print(mse_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c952fd1-f985-4683-b84c-f1b3cda8b909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
