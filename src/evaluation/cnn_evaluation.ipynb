{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5604aa68-cdae-4f79-97d3-34e182a0ca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, tensorflow as tf\n",
    "import sys, time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dropout, MaxPooling1D, GlobalAveragePooling1D, Conv1DTranspose, LSTM, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137720cc-886d-4641-9490-0bf697082df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - ss_res/(ss_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "510cc1b9-44b9-4027-83c2-9345aca08abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 0 # 0 = th v air, 1 = el v sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414b045b-f57d-495c-beb8-b710c55370dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [0,3] if MODEL==0 else [1,2]\n",
    "model_name = 'th_v_air' if MODEL==0 else 'el_v_sky'\n",
    "\n",
    "base_data_train, base_data_test = np.load('../../data/training_data/training_data_1month.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e3ed8d-a134-4ffb-94de-6e79786ca695",
   "metadata": {},
   "source": [
    "<h2> Scale Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90635f26-def5-40d8-a820-3150b41f9a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 730, 4) (108, 730, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "base_data_train, base_data_test = np.load('../../data/training_data/training_data_1month.npy', allow_pickle=True)\n",
    "scalers = {var_name: MinMaxScaler(feature_range=(-1,1)) for var_name in ['G.air.T', 'G.E_th_I', 'G.sky.T', 'G.E_el_I']}\n",
    "\n",
    "air_var, sky_var, el_var, th_var = base_data_train[:,:,0], base_data_train[:,:,1], base_data_train[:,:,2], base_data_train[:,:,3]\n",
    "air_var_test, sky_var_test, el_var_test, th_var_test = base_data_test[:,:,0], base_data_test[:,:,1], base_data_test[:,:,2], base_data_test[:,:,3]\n",
    "\n",
    "scaled_data_train = np.stack((scalers['G.air.T'].fit_transform(air_var),\n",
    "                             scalers['G.sky.T'].fit_transform(sky_var),\n",
    "                             scalers['G.E_el_I'].fit_transform(el_var),\n",
    "                             scalers['G.E_th_I'].fit_transform(th_var)), axis=-1)\n",
    "scaled_data_test = np.stack((scalers['G.air.T'].fit_transform(air_var),\n",
    "                             scalers['G.sky.T'].fit_transform(sky_var),\n",
    "                             scalers['G.E_el_I'].fit_transform(el_var),\n",
    "                             scalers['G.E_th_I'].fit_transform(th_var)), axis=-1)\n",
    "print(scaled_data_train.shape, scaled_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be189d7-6067-4652-8dc0-f688acece12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 730, 2) (12, 730, 2) (108, 730, 2) (12, 730, 2)\n"
     ]
    }
   ],
   "source": [
    "def split_base_data(base_data_train, base_data_test, th_indices=[0, 3], el_indices=[1, 2]):\n",
    "    th_base_data_train, th_base_data_test = base_data_train[:, :, th_indices], base_data_test[:, :, th_indices]\n",
    "    el_base_data_train, el_base_data_test = base_data_train[:, :, el_indices], base_data_test[:, :, el_indices]\n",
    "    return th_base_data_train, th_base_data_test, el_base_data_train, el_base_data_test\n",
    "\n",
    "th_base_data_train, th_base_data_test, el_base_data_train, el_base_data_test = split_base_data(base_data_train, base_data_test)\n",
    "print(th_base_data_train.shape, th_base_data_test.shape, el_base_data_train.shape, el_base_data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff891f3-88f4-4fec-95fb-c99b90a73ace",
   "metadata": {},
   "source": [
    "<h2> CNN Models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a190fe07-f580-4d55-9daf-dbcbe79b8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=24, activation='relu', input_shape=(input_shape)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Conv1D(filters=64, kernel_size=24, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(730, activation='linear')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a72256e-8e9d-4013-90ce-1b4cae833dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn(training_data, th_or_el):\n",
    "    X_train = training_data[:,:,0].reshape(-1,730,1)\n",
    "    y_train = training_data[:,:,1]\n",
    "\n",
    "    if th_or_el == 0:\n",
    "        X_test = scaled_data_test[:,:,0].reshape(-1, 730, 1)  \n",
    "        y_test = scaled_data_test[:,:,3]\n",
    "    else:\n",
    "        X_test = scaled_data_test[:,:,1].reshape(-1, 730, 1)  \n",
    "        y_test = scaled_data_test[:,:,2]\n",
    "\n",
    "    X_train, X_train_val, y_train, y_train_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)\n",
    "                                                                  \n",
    "    model = create_cnn((X_train.shape[1], X_train.shape[2]))\n",
    "    model.compile(optimizer=Adam(), loss='mse', metrics=['mse', 'mae'])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='mse', patience=10, verbose=1, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='mse', factor=0.5, patience=5, verbose=1)\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=16, callbacks=[early_stopping, reduce_lr], verbose=0, validation_data=(X_train_val, y_train_val))\n",
    "\n",
    "    loss, mse, mae = model.evaluate(X_test, y_test)\n",
    "    r2 = r_squared(tf.convert_to_tensor(y_test, dtype=tf.float32), tf.convert_to_tensor(model.predict(X_test), dtype=tf.float32))\n",
    "    \n",
    "    return {'mse':mse, 'mae':mae, 'r2':r2.numpy()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc6be8c1-0a57-414d-8461-866b41a76655",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reps = 20\n",
    "\n",
    "def test_cnn_wrapper(data, th_or_el=0):\n",
    "    mse, mae, r2 = 0, 0, 0\n",
    "\n",
    "    # Run each CNN training 10 times to ensure results are significant and not outliers\n",
    "    for i in range(num_reps):\n",
    "        print(f'RUN: {i}')\n",
    "        results = test_cnn(np.random.permutation(data), th_or_el) # permuting the data for each run just to ensure full shuffling\n",
    "        mse += results['mse']\n",
    "        mae += results['mae']\n",
    "        r2  += results['r2']\n",
    "\n",
    "    return {'mse':mse/num_reps, 'mae':mae/num_reps, 'r2':r2/num_reps}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa06e5-c9b5-461f-bc7a-98375e2994e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a02e7804-5dee-469e-881c-6d0f2648e6d5",
   "metadata": {},
   "source": [
    "<h2> Load data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "763f646c-f6c2-45e3-bb6c-f2ce3b45bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_path, context, dataset_names):\n",
    "    datasets = {}\n",
    "    for name in dataset_names:\n",
    "        file_path = f'{base_path}/{context}_{name}_generated_samples.npy'\n",
    "        datasets[name] = np.load(file_path, allow_pickle=True)\n",
    "    return datasets\n",
    "\n",
    "base_path_vae = '../../data/vae_synthetic_data/'\n",
    "base_path_gan = '../../data/gan_synthetic_data/'\n",
    "th_context = 'th_v_air'\n",
    "el_context = 'el_v_sky'\n",
    "\n",
    "th_vae_datasets = ['b20l5', 'b4l10', 'b16l10', 'b8l20', 'b4l5', 'b16l5', 'b20l3', 'b24l15', 'b8l15', 'b24l50']\n",
    "th_gan_datasets = ['b32e500', 'b8e1000', 'b20e100', 'b32e100', 'b6e100', 'b8e500']\n",
    "\n",
    "th_vae_data = load_data(base_path_vae, th_context, th_vae_datasets)\n",
    "th_gan_data = load_data(base_path_gan, th_context, th_gan_datasets)\n",
    "\n",
    "el_vae_datasets = []\n",
    "el_gan_datasets = []\n",
    "\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a44b057e-c56d-426e-a61a-0fc5c5d6706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [(1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2)]\n",
      "10 [(1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(len(th_vae_data), [th_vae_data[th_vae_datasets[i]].shape for i in range(len(th_vae_data))])\n",
    "print(len(th_vae_data), [th_gan_data[th_gan_datasets[i]].shape for i in range(len(th_gan_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47ab1da6-24d3-494d-b94b-6d5b9834e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_cnn(data_dicts, model_type, column_index, base_path='../../data/evaluation_results/'):\n",
    "    for dataset_name, dataset in data_dicts.items():\n",
    "        cnn_test_results = test_cnn_wrapper(dataset[0:216, :, :], column_index)\n",
    "\n",
    "        result_df = pd.DataFrame(cnn_test_results, index=[0])\n",
    "        result_file_name = f'{base_path}{model_type}_{\"th\" if column_index==0 else \"el\"}_{dataset_name}.csv'\n",
    "        result_df.to_csv(result_file_name)\n",
    "        print(f'CNN results for {dataset_name}: {result_df}')\n",
    "        print(f'Saved CNN evaluation results for {dataset_name} to: {result_file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f7849-ccd0-4196-9af6-87c4a1edba3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0\n",
      "WARNING:tensorflow:From C:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1478 - mse: 0.1478 - mae: 0.2961\n",
      "4/4 [==============================] - 0s 9ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1404 - mse: 0.1404 - mae: 0.2800\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "RUN: 2\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_save_cnn(th_vae_data, 'vae', 0)\n",
    "evaluate_and_save_cnn(th_gan_data, 'gan', 0)\n",
    "\n",
    "#evaluate_and_save_cnn(el_vae_data, 'el', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5dd46-1f23-4a8b-abeb-323955047d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c6469f-45e2-43c1-80d9-f5c4f923e13f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
