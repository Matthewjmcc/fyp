{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5604aa68-cdae-4f79-97d3-34e182a0ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, tensorflow as tf\n",
    "import sys, time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dropout, MaxPooling1D, GlobalAveragePooling1D, Conv1DTranspose, LSTM, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.precision', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "137720cc-886d-4641-9490-0bf697082df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - ss_res/(ss_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "414b045b-f57d-495c-beb8-b710c55370dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_train, base_data_test = np.load('../../data/training_data/training_data_1month.npy', allow_pickle=True)\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e3ed8d-a134-4ffb-94de-6e79786ca695",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2> Scale Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90635f26-def5-40d8-a820-3150b41f9a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 730, 4) (108, 730, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "base_data_train, base_data_test = np.load('../../data/training_data/training_data_1month.npy', allow_pickle=True)\n",
    "scalers = {var_name: MinMaxScaler(feature_range=(-1,1)) for var_name in ['G.air.T', 'G.E_th_I', 'G.sky.T', 'G.E_el_I']}\n",
    "\n",
    "air_var, sky_var, el_var, th_var = base_data_train[:,:,0], base_data_train[:,:,1], base_data_train[:,:,2], base_data_train[:,:,3]\n",
    "air_var_test, sky_var_test, el_var_test, th_var_test = base_data_test[:,:,0], base_data_test[:,:,1], base_data_test[:,:,2], base_data_test[:,:,3]\n",
    "\n",
    "scaled_data_train = np.stack((scalers['G.air.T'].fit_transform(air_var),\n",
    "                             scalers['G.sky.T'].fit_transform(sky_var),\n",
    "                             scalers['G.E_el_I'].fit_transform(el_var),\n",
    "                             scalers['G.E_th_I'].fit_transform(th_var)), axis=-1)\n",
    "scaled_data_test = np.stack((scalers['G.air.T'].fit_transform(air_var),\n",
    "                             scalers['G.sky.T'].fit_transform(sky_var),\n",
    "                             scalers['G.E_el_I'].fit_transform(el_var),\n",
    "                             scalers['G.E_th_I'].fit_transform(th_var)), axis=-1)\n",
    "print(scaled_data_train.shape, scaled_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1be189d7-6067-4652-8dc0-f688acece12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 730, 2) (12, 730, 2) (108, 730, 2) (12, 730, 2)\n"
     ]
    }
   ],
   "source": [
    "def split_base_data(base_data_train, base_data_test, th_indices=[0, 3], el_indices=[1, 2]):\n",
    "    th_base_data_train, th_base_data_test = base_data_train[:, :, th_indices], base_data_test[:, :, th_indices]\n",
    "    el_base_data_train, el_base_data_test = base_data_train[:, :, el_indices], base_data_test[:, :, el_indices]\n",
    "    return th_base_data_train, th_base_data_test, el_base_data_train, el_base_data_test\n",
    "\n",
    "th_base_data_train, th_base_data_test, el_base_data_train, el_base_data_test = split_base_data(base_data_train, base_data_test)\n",
    "print(th_base_data_train.shape, th_base_data_test.shape, el_base_data_train.shape, el_base_data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff891f3-88f4-4fec-95fb-c99b90a73ace",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2> CNN Models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a190fe07-f580-4d55-9daf-dbcbe79b8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=24, activation='relu', input_shape=(input_shape)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Conv1D(filters=64, kernel_size=24, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(730, activation='linear')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a72256e-8e9d-4013-90ce-1b4cae833dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn(training_data, th_or_el):\n",
    "    X_train = training_data[:,:,0].reshape(-1,730,1)\n",
    "    y_train = training_data[:,:,1]\n",
    "\n",
    "    if th_or_el == 0:\n",
    "        X_test = scaled_data_test[:,:,0].reshape(-1, 730, 1)  \n",
    "        y_test = scaled_data_test[:,:,3]\n",
    "    else:\n",
    "        X_test = scaled_data_test[:,:,1].reshape(-1, 730, 1)  \n",
    "        y_test = scaled_data_test[:,:,2]\n",
    "\n",
    "    X_train, X_train_val, y_train, y_train_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)\n",
    "                                                                  \n",
    "    model = create_cnn((X_train.shape[1], X_train.shape[2]))\n",
    "    model.compile(optimizer=Adam(), loss='mse', metrics=['mse', 'mae'])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='mse', patience=10, verbose=1, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='mse', factor=0.5, patience=5, verbose=1)\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=16, callbacks=[early_stopping, reduce_lr], verbose=0, validation_data=(X_train_val, y_train_val))\n",
    "\n",
    "    loss, mse, mae = model.evaluate(X_test, y_test)\n",
    "    r2 = r_squared(tf.convert_to_tensor(y_test, dtype=tf.float32), tf.convert_to_tensor(model.predict(X_test), dtype=tf.float32))\n",
    "    \n",
    "    return {'mse':mse, 'mae':mae, 'r2':r2.numpy()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc6be8c1-0a57-414d-8461-866b41a76655",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reps = 100\n",
    "\n",
    "def test_cnn_wrapper(data, th_or_el=0):\n",
    "    mse, mae, r2 = [], [], []\n",
    "    \n",
    "    # Run each CNN training 10 times to ensure results are significant and not outliers\n",
    "    for i in range(num_reps):\n",
    "        print(f'RUN: {i}')\n",
    "        results = test_cnn(np.random.permutation(data), th_or_el) # permuting the data for each run just to ensure full shuffling\n",
    "        mse.append(results['mse'])\n",
    "        mae.append(results['mae'])\n",
    "        r2.append(results['r2'])\n",
    "\n",
    "    return {'mse':mse, 'mae':mae, 'r2':r2}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa06e5-c9b5-461f-bc7a-98375e2994e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a02e7804-5dee-469e-881c-6d0f2648e6d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2> Load data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "763f646c-f6c2-45e3-bb6c-f2ce3b45bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches=[2,4,6,8,10,12,16,20,24,32]\n",
    "epochs=[100,500,1000,2000,5000]\n",
    "\n",
    "def load_data(base_path, context, dataset_names):\n",
    "    datasets = {}\n",
    "    for name in dataset_names:\n",
    "        file_path = f'{base_path}/{context}_{name}_generated_samples.npy'\n",
    "        datasets[name] = np.load(file_path, allow_pickle=True)\n",
    "    return datasets\n",
    "\n",
    "base_path_vae = '../../data/vae_synthetic_data/'\n",
    "base_path_gan = '../../data/gan_synthetic_data/'\n",
    "th_context = 'th_v_air'\n",
    "el_context = 'el_v_sky'\n",
    "\n",
    "th_vae_datasets = ['b4l5', 'b4l10', 'b8l15', 'b8l20', 'b16l5', 'b20l3', 'b20l5', 'b24l15', 'b24l50'] #9\n",
    "th_gan_datasets = ['b6e100', 'b8e1000', 'b8e2000', 'b12e5000', 'b16e2000', 'b20e100', 'b32e100', 'b32e500'] # 8\n",
    "\n",
    "th_vae_data = load_data(base_path_vae, th_context, th_vae_datasets)\n",
    "th_gan_data = load_data(base_path_gan, th_context, th_gan_datasets)\n",
    "\n",
    "el_vae_datasets = ['b4l3', 'b8l10', 'b20l3', 'b20l20', 'b24l3', 'b32l3', 'b32l5'] #7\n",
    "el_gan_datasets = ['b4e100','b10e100','b16e500','b20e500', 'b20e2000', 'b24e1000', 'b32e1000'] # 7\n",
    "\n",
    "el_vae_data = load_data(base_path_vae, el_context, el_vae_datasets)\n",
    "el_gan_data = load_data(base_path_gan, el_context, el_gan_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a44b057e-c56d-426e-a61a-0fc5c5d6706a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [(1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2)]\n",
      "8 [(1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2)]\n",
      "7 [(1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2)]\n",
      "7 [(1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(len(th_vae_data), [th_vae_data[th_vae_datasets[i]].shape for i in range(len(th_vae_data))])\n",
    "print(len(th_gan_data), [th_gan_data[th_gan_datasets[i]].shape for i in range(len(th_gan_data))])\n",
    "\n",
    "print(len(el_vae_data), [el_vae_data[el_vae_datasets[i]].shape for i in range(len(el_vae_data))])\n",
    "print(len(el_gan_data), [el_gan_data[el_gan_datasets[i]].shape for i in range(len(el_gan_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f6341-ad77-404e-a731-5d672b788255",
   "metadata": {},
   "source": [
    "<h2> Train CNNs </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e32ba9-d65f-4a89-ab8a-d895cfc9a5cd",
   "metadata": {},
   "source": [
    "<h3> Ground Truth Datasets </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3414deb-dd19-47d4-82b9-c03f4137584a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0983 - mse: 0.0983 - mae: 0.2335\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0973 - mse: 0.0973 - mae: 0.2308\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1053 - mse: 0.1053 - mae: 0.2429\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1008 - mse: 0.1008 - mae: 0.2336\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1032 - mse: 0.1032 - mae: 0.2356\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1033 - mse: 0.1033 - mae: 0.2437\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0956 - mse: 0.0956 - mae: 0.2261\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0953 - mse: 0.0953 - mae: 0.2245\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0972 - mse: 0.0972 - mae: 0.2371\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0967 - mse: 0.0967 - mae: 0.2362\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0949 - mse: 0.0949 - mae: 0.2399\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 11\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0963 - mse: 0.0963 - mae: 0.2261\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 12\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1009 - mse: 0.1009 - mae: 0.2330\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 13\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1015 - mse: 0.1015 - mae: 0.2455\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 14\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0947 - mse: 0.0947 - mae: 0.2243\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 15\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1064 - mse: 0.1064 - mae: 0.2458\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 16\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0954 - mse: 0.0954 - mae: 0.2337\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 17\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0944 - mse: 0.0944 - mae: 0.2308\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 18\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0965 - mse: 0.0965 - mae: 0.2334\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 19\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0937 - mse: 0.0937 - mae: 0.2308\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 20\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1045 - mse: 0.1045 - mae: 0.2425\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 21\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0912 - mse: 0.0912 - mae: 0.2226\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 22\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0969 - mse: 0.0969 - mae: 0.2268\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 23\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1024 - mse: 0.1024 - mae: 0.2383\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 24\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1093 - mse: 0.1093 - mae: 0.2518\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 25\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2164\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 26\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1102 - mse: 0.1102 - mae: 0.2538\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 27\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1090 - mse: 0.1090 - mae: 0.2453\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 28\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1055 - mse: 0.1055 - mae: 0.2425\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 29\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1021 - mse: 0.1021 - mae: 0.2390\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 30\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1015 - mse: 0.1015 - mae: 0.2331\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 31\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0945 - mse: 0.0945 - mae: 0.2327\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 32\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1038 - mse: 0.1038 - mae: 0.2489\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 33\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1016 - mse: 0.1016 - mae: 0.2355\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 34\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0966 - mse: 0.0966 - mae: 0.2245\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 35\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0961 - mse: 0.0961 - mae: 0.2300\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 36\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0925 - mse: 0.0925 - mae: 0.2161\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 37\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1036 - mse: 0.1036 - mae: 0.2412\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 38\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0993 - mse: 0.0993 - mae: 0.2363\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 39\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0993 - mse: 0.0993 - mae: 0.2289\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0950 - mse: 0.0950 - mae: 0.2325\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 41\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0981 - mse: 0.0981 - mae: 0.2319\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 42\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0922 - mse: 0.0922 - mae: 0.2174\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 43\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0903 - mse: 0.0903 - mae: 0.2147\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 44\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1002 - mse: 0.1002 - mae: 0.2364\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 45\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0953 - mse: 0.0953 - mae: 0.2246\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 46\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0984 - mse: 0.0984 - mae: 0.2275\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 47\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1062 - mse: 0.1062 - mae: 0.2517\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 48\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0971 - mse: 0.0971 - mae: 0.2369\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 49\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0992 - mse: 0.0992 - mae: 0.2262\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1055 - mse: 0.1055 - mae: 0.2499\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 51\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0971 - mse: 0.0971 - mae: 0.2255\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 52\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1006 - mse: 0.1006 - mae: 0.2465\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 53\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0963 - mse: 0.0963 - mae: 0.2271\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 54\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0911 - mse: 0.0911 - mae: 0.2226\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 55\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0958 - mse: 0.0958 - mae: 0.2314\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 56\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0968 - mse: 0.0968 - mae: 0.2265\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 57\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1057 - mse: 0.1057 - mae: 0.2513\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 58\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0929 - mse: 0.0929 - mae: 0.2258\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 59\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0973 - mse: 0.0973 - mae: 0.2252\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0992 - mse: 0.0992 - mae: 0.2383\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 61\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1059 - mse: 0.1059 - mae: 0.2463\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 62\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1037 - mse: 0.1037 - mae: 0.2362\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 63\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0979 - mse: 0.0979 - mae: 0.2353\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 64\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1066 - mse: 0.1066 - mae: 0.2403\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 65\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1034 - mse: 0.1034 - mae: 0.2427\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 66\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0995 - mse: 0.0995 - mae: 0.2394\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 67\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0964 - mse: 0.0964 - mae: 0.2331\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 68\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0992 - mse: 0.0992 - mae: 0.2373\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 69\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1015 - mse: 0.1015 - mae: 0.2355\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 70\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0959 - mse: 0.0959 - mae: 0.2323\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 71\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1076 - mse: 0.1076 - mae: 0.2550\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 72\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0959 - mse: 0.0959 - mae: 0.2247\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 73\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0925 - mse: 0.0925 - mae: 0.2298\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 74\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1033 - mse: 0.1033 - mae: 0.2481\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 75\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1017 - mse: 0.1017 - mae: 0.2330\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 76\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1002 - mse: 0.1002 - mae: 0.2326\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 77\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0981 - mse: 0.0981 - mae: 0.2309\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 78\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1045 - mse: 0.1045 - mae: 0.2398\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 79\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0927 - mse: 0.0927 - mae: 0.2173\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 80\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1036 - mse: 0.1036 - mae: 0.2396\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 81\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1066 - mse: 0.1066 - mae: 0.2551\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 82\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1035 - mse: 0.1035 - mae: 0.2383\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 83\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0978 - mse: 0.0978 - mae: 0.2330\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 84\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0992 - mse: 0.0992 - mae: 0.2322\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 85\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0971 - mse: 0.0971 - mae: 0.2293\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 86\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0883 - mse: 0.0883 - mae: 0.2160\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 87\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1052 - mse: 0.1052 - mae: 0.2469\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 88\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0968 - mse: 0.0968 - mae: 0.2296\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 89\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0976 - mse: 0.0976 - mae: 0.2322\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 90\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0908 - mse: 0.0908 - mae: 0.2207\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 91\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0908 - mse: 0.0908 - mae: 0.2134\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 92\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1019 - mse: 0.1019 - mae: 0.2461\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 93\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0947 - mse: 0.0947 - mae: 0.2264\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 94\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0957 - mse: 0.0957 - mae: 0.2246\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 95\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1043 - mse: 0.1043 - mae: 0.2450\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 96\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1026 - mse: 0.1026 - mae: 0.2363\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 97\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1057 - mse: 0.1057 - mae: 0.2439\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 98\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0954 - mse: 0.0954 - mae: 0.2218\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 99\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1051 - mse: 0.1051 - mae: 0.2456\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2621 - mse: 0.2621 - mae: 0.3787\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2640 - mse: 0.2640 - mae: 0.3944\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3511 - mse: 0.3511 - mae: 0.4611\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2770 - mse: 0.2770 - mae: 0.3941\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3242 - mse: 0.3242 - mae: 0.4398\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2810 - mse: 0.2810 - mae: 0.4070\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2831 - mse: 0.2831 - mae: 0.4020\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2744 - mse: 0.2744 - mae: 0.3960\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2783 - mse: 0.2783 - mae: 0.3973\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2692 - mse: 0.2692 - mae: 0.3943\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2864 - mse: 0.2864 - mae: 0.4037\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 11\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2860 - mse: 0.2860 - mae: 0.4045\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 12\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2694 - mse: 0.2694 - mae: 0.3912\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 13\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3038 - mse: 0.3038 - mae: 0.4258\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 14\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2859 - mse: 0.2859 - mae: 0.4073\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 15\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2891 - mse: 0.2891 - mae: 0.4122\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 16\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2890 - mse: 0.2890 - mae: 0.4090\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 17\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2994 - mse: 0.2994 - mae: 0.4218\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 18\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2744 - mse: 0.2744 - mae: 0.4063\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 19\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3061 - mse: 0.3061 - mae: 0.4279\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2774 - mse: 0.2774 - mae: 0.3986\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 21\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2962 - mse: 0.2962 - mae: 0.4230\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 22\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2907 - mse: 0.2907 - mae: 0.4111\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 23\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2778 - mse: 0.2778 - mae: 0.4049\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 24\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2753 - mse: 0.2753 - mae: 0.4017\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 25\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2843 - mse: 0.2843 - mae: 0.4074\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 26\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2872 - mse: 0.2872 - mae: 0.4114\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 27\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2642 - mse: 0.2642 - mae: 0.3795\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 28\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2985 - mse: 0.2985 - mae: 0.4178\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 29\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2996 - mse: 0.2996 - mae: 0.4239\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2839 - mse: 0.2839 - mae: 0.4052\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 31\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2955 - mse: 0.2955 - mae: 0.4204\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 32\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2767 - mse: 0.2767 - mae: 0.3985\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 33\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2526 - mse: 0.2526 - mae: 0.3757\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 34\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2862 - mse: 0.2862 - mae: 0.4097\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 35\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2819 - mse: 0.2819 - mae: 0.4084\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 36\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2848 - mse: 0.2848 - mae: 0.4077\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 37\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2779 - mse: 0.2779 - mae: 0.4006\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 38\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2830 - mse: 0.2830 - mae: 0.4108\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 39\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2943 - mse: 0.2943 - mae: 0.4101\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3266 - mse: 0.3266 - mae: 0.4495\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 41\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2709 - mse: 0.2709 - mae: 0.3966\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 42\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2720 - mse: 0.2720 - mae: 0.3964\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 43\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2455 - mse: 0.2455 - mae: 0.3716\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 44\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2847 - mse: 0.2847 - mae: 0.4050\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 45\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2828 - mse: 0.2828 - mae: 0.4009\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 46\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2714 - mse: 0.2714 - mae: 0.3930\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 47\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2798 - mse: 0.2798 - mae: 0.3984\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 48\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3557 - mse: 0.3557 - mae: 0.4601\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 49\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3391 - mse: 0.3391 - mae: 0.4567\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2918 - mse: 0.2918 - mae: 0.4115\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 51\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2663 - mse: 0.2663 - mae: 0.3951\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 52\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2648 - mse: 0.2648 - mae: 0.3910\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 53\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3005 - mse: 0.3005 - mae: 0.4197\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 54\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2841 - mse: 0.2841 - mae: 0.4040\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 55\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2907 - mse: 0.2907 - mae: 0.4126\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 56\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2641 - mse: 0.2641 - mae: 0.3832\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 57\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2977 - mse: 0.2977 - mae: 0.4202\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 58\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2698 - mse: 0.2698 - mae: 0.3969\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 59\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2914 - mse: 0.2914 - mae: 0.4151\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2675 - mse: 0.2675 - mae: 0.3905\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 61\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2761 - mse: 0.2761 - mae: 0.3994\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 62\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3079 - mse: 0.3079 - mae: 0.4294\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 63\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3181 - mse: 0.3181 - mae: 0.4344\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 64\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3000 - mse: 0.3000 - mae: 0.4192\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 65\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2659 - mse: 0.2659 - mae: 0.3923\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 66\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2735 - mse: 0.2735 - mae: 0.3938\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 67\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3145 - mse: 0.3145 - mae: 0.4362\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 68\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3180 - mse: 0.3180 - mae: 0.4342\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 69\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2858 - mse: 0.2858 - mae: 0.4097\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 70\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2789 - mse: 0.2789 - mae: 0.4035\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 71\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3050 - mse: 0.3050 - mae: 0.4276\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 72\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3041 - mse: 0.3041 - mae: 0.4236\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 73\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3077 - mse: 0.3077 - mae: 0.4214\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 74\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2915 - mse: 0.2915 - mae: 0.4153\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2805 - mse: 0.2805 - mae: 0.4014\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 76\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3054 - mse: 0.3054 - mae: 0.4194\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 77\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2760 - mse: 0.2760 - mae: 0.3961\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 78\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2803 - mse: 0.2803 - mae: 0.4020\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 79\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3030 - mse: 0.3030 - mae: 0.4203\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 80\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3056 - mse: 0.3056 - mae: 0.4293\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 81\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2926 - mse: 0.2926 - mae: 0.4099\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 82\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2634 - mse: 0.2634 - mae: 0.3854\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 83\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2930 - mse: 0.2930 - mae: 0.4202\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 84\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3065 - mse: 0.3065 - mae: 0.4215\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 85\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3261 - mse: 0.3261 - mae: 0.4437\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 86\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2887 - mse: 0.2887 - mae: 0.4097\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 87\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2617 - mse: 0.2617 - mae: 0.3936\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 88\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2786 - mse: 0.2786 - mae: 0.3949\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 89\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2937 - mse: 0.2937 - mae: 0.4102\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 90\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2670 - mse: 0.2670 - mae: 0.3915\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 91\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2749 - mse: 0.2749 - mae: 0.3955\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 92\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3055 - mse: 0.3055 - mae: 0.4236\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 93\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3091 - mse: 0.3091 - mae: 0.4357\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 94\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2956 - mse: 0.2956 - mae: 0.4177\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2727 - mse: 0.2727 - mae: 0.3990\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 96\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2991 - mse: 0.2991 - mae: 0.4211\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 97\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2856 - mse: 0.2856 - mae: 0.4051\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 98\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2837 - mse: 0.2837 - mae: 0.4076\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 99\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2696 - mse: 0.2696 - mae: 0.3918\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(test_cnn_wrapper(scaled_data_train[:,:,[0,3]], 0)).to_csv('../../data/evaluation_results/th_gt.csv', index=False)\n",
    "pd.DataFrame(test_cnn_wrapper(scaled_data_train[:,:,[1,2]], 1)).to_csv('../../data/evaluation_results/el_gt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a587c960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09846784219145771 0.286872461438179\n"
     ]
    }
   ],
   "source": [
    "th_gt, el_gt = pd.read_csv('../../data/evaluation_results/th_gt.csv'), pd.read_csv('../../data/evaluation_results/el_gt.csv')\n",
    "\n",
    "print(np.mean(th_gt['mse']), np.mean(el_gt['mse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c34e06-8cec-455c-9750-c3dedae82445",
   "metadata": {},
   "source": [
    "<h3> Synthetic Datasets </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47ab1da6-24d3-494d-b94b-6d5b9834e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_cnn(data_dicts, model_type, column_index, base_path='../../data/evaluation_results/'):\n",
    "    for dataset_name, dataset in data_dicts.items():\n",
    "        cnn_test_results = test_cnn_wrapper(dataset[0:216, :, :], column_index)\n",
    "\n",
    "        result_df = pd.DataFrame(cnn_test_results)\n",
    "        result_file_name = f'{base_path}{model_type}_{\"th\" if column_index==0 else \"el\"}_{dataset_name}.csv'\n",
    "        result_df.to_csv(result_file_name)\n",
    "        print(f'CNN results for {dataset_name}: {result_df}')\n",
    "        print(f'Saved CNN evaluation results for {dataset_name} to: {result_file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb1f7849-ccd0-4196-9af6-87c4a1edba3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 14:44:19.578613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 154 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1\n",
      "2024-04-14 14:44:19.594110: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1101] failed to allocate 154.25MiB (161742848 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2024-04-14 14:44:21.044433: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:459] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2024-04-14 14:44:21.044555: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:463] Memory usage: 12845056 bytes free, 8504934400 bytes total.\n",
      "2024-04-14 14:44:21.044648: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Possibly insufficient driver version: 530.30.2\n",
      "2024-04-14 14:44:21.044705: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at conv_ops_impl.h:1199 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node sequential/conv1d/Conv1D defined at (most recent call last):\n  File \"/opt/anaconda3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/opt/anaconda3/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 199, in start\n\n  File \"/opt/anaconda3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/opt/anaconda3/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n\n  File \"/opt/anaconda3/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n\n  File \"/tmp/ipykernel_4160/1341728716.py\", line 1, in <module>\n\n  File \"/tmp/ipykernel_4160/2795280775.py\", line 3, in evaluate_and_save_cnn\n\n  File \"/tmp/ipykernel_4160/2498205377.py\", line 9, in test_cnn_wrapper\n\n  File \"/tmp/ipykernel_4160/3119030451.py\", line 19, in test_cnn\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n\nDNN library is not found.\n\t [[{{node sequential/conv1d/Conv1D}}]] [Op:__inference_train_function_1353]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate_and_save_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mth_vae_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvae\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m evaluate_and_save_cnn(th_gan_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgan\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m, in \u001b[0;36mevaluate_and_save_cnn\u001b[0;34m(data_dicts, model_type, column_index, base_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_and_save_cnn\u001b[39m(data_dicts, model_type, column_index, base_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/evaluation_results/\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset_name, dataset \u001b[38;5;129;01min\u001b[39;00m data_dicts\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 3\u001b[0m         cnn_test_results \u001b[38;5;241m=\u001b[39m \u001b[43mtest_cnn_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m216\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m         result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(cnn_test_results)\n\u001b[1;32m      6\u001b[0m         result_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mth\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m column_index\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m, in \u001b[0;36mtest_cnn_wrapper\u001b[0;34m(data, th_or_el)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_reps):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRUN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mtest_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermutation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth_or_el\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# permuting the data for each run just to ensure full shuffling\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     mse\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m     mae\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m, in \u001b[0;36mtest_cnn\u001b[0;34m(training_data, th_or_el)\u001b[0m\n\u001b[1;32m     17\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m loss, mse, mae \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m     22\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r_squared(tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(y_test, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32), tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(model\u001b[38;5;241m.\u001b[39mpredict(X_test), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node sequential/conv1d/Conv1D defined at (most recent call last):\n  File \"/opt/anaconda3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/opt/anaconda3/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 199, in start\n\n  File \"/opt/anaconda3/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/opt/anaconda3/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n\n  File \"/opt/anaconda3/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n\n  File \"/opt/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n\n  File \"/tmp/ipykernel_4160/1341728716.py\", line 1, in <module>\n\n  File \"/tmp/ipykernel_4160/2795280775.py\", line 3, in evaluate_and_save_cnn\n\n  File \"/tmp/ipykernel_4160/2498205377.py\", line 9, in test_cnn_wrapper\n\n  File \"/tmp/ipykernel_4160/3119030451.py\", line 19, in test_cnn\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n\n  File \"/home/mjmc2/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n\nDNN library is not found.\n\t [[{{node sequential/conv1d/Conv1D}}]] [Op:__inference_train_function_1353]"
     ]
    }
   ],
   "source": [
    "evaluate_and_save_cnn(th_vae_data, 'vae', 0)\n",
    "evaluate_and_save_cnn(th_gan_data, 'gan', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7fd40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_save_cnn(el_vae_data, 'vae', 1)\n",
    "evaluate_and_save_cnn(el_gan_data, 'gan', 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a037f92-ded3-42b4-aefc-306d635935c0",
   "metadata": {},
   "source": [
    "<h3> Blended Datasets </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f99b5a33-68f9-415e-82c3-42ff685781ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_cnn_blended(data_dicts, model_type, column_index, base_path='../../data/evaluation_results/'):\n",
    "    for dataset_name, dataset in data_dicts.items():\n",
    "        scaled_data = scaled_data_train[:,:,[0,3]] if column_index==0 else scaled_data_train[:,:,[1,2]]\n",
    "        cnn_test_results = test_cnn_wrapper(np.concatenate((scaled_data, dataset[0:216,:,:]), axis=0), column_index)\n",
    "\n",
    "        result_df = pd.DataFrame(cnn_test_results)\n",
    "        result_file_name = f'{base_path}{model_type}_blended_{\"th\" if column_index==0 else \"el\"}_{dataset_name}.csv'\n",
    "        result_df.to_csv(result_file_name)\n",
    "        print(f'CNN results for {dataset_name}: {result_df}')\n",
    "        print(f'Saved CNN evaluation results for {dataset_name} to: {result_file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b4d32-80d8-4d5f-b767-7a26ab07af24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_and_save_cnn_blended(th_vae_data, 'vae', 0)\n",
    "evaluate_and_save_cnn_blended(th_gan_data, 'gan', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e12066c1-16c7-4313-8c7e-04229b7a4910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3205 - mse: 0.3205 - mae: 0.4372\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3218 - mse: 0.3218 - mae: 0.4411\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3123 - mse: 0.3123 - mae: 0.4293\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2751 - mse: 0.2751 - mae: 0.4008\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2801 - mse: 0.2801 - mae: 0.4031\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3252 - mse: 0.3252 - mae: 0.4391\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2820 - mse: 0.2820 - mae: 0.4005\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3018 - mse: 0.3018 - mae: 0.4191\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3100 - mse: 0.3100 - mae: 0.4239\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2905 - mse: 0.2905 - mae: 0.4094\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b4l3:         mse       mae       r2\n",
      "0  0.301946  0.420358  0.56735\n",
      "Saved CNN evaluation results for b4l3 to: ../../data/evaluation_results/vae_blended_el_b4l3.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2919 - mse: 0.2919 - mae: 0.4169\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2942 - mse: 0.2942 - mae: 0.4155\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2829 - mse: 0.2829 - mae: 0.4097\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2541 - mse: 0.2541 - mae: 0.3850\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2772 - mse: 0.2772 - mae: 0.4066\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2786 - mse: 0.2786 - mae: 0.4086\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3218 - mse: 0.3218 - mae: 0.4419\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3120 - mse: 0.3120 - mae: 0.4330\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3484 - mse: 0.3484 - mae: 0.4620\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3081 - mse: 0.3081 - mae: 0.4284\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b8l10:         mse       mae       r2\n",
      "0  0.296928  0.420767  0.57454\n",
      "Saved CNN evaluation results for b8l10 to: ../../data/evaluation_results/vae_blended_el_b8l10.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2310 - mse: 0.2310 - mae: 0.3563\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2563 - mse: 0.2563 - mae: 0.3803\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2774 - mse: 0.2774 - mae: 0.3959\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2254 - mse: 0.2254 - mae: 0.3504\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2331 - mse: 0.2331 - mae: 0.3656\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2788 - mse: 0.2788 - mae: 0.4031\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2822 - mse: 0.2822 - mae: 0.4004\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2316 - mse: 0.2316 - mae: 0.3653\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2652 - mse: 0.2652 - mae: 0.3885\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2548 - mse: 0.2548 - mae: 0.3831\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b20l3:         mse       mae        r2\n",
      "0  0.253592  0.378871  0.636635\n",
      "Saved CNN evaluation results for b20l3 to: ../../data/evaluation_results/vae_blended_el_b20l3.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3507 - mse: 0.3507 - mae: 0.4612\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3315 - mse: 0.3315 - mae: 0.4481\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3312 - mse: 0.3312 - mae: 0.4562\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2836 - mse: 0.2836 - mae: 0.4058\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2704 - mse: 0.2704 - mae: 0.3993\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3650 - mse: 0.3650 - mae: 0.4648\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4002 - mse: 0.4002 - mae: 0.5016\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2902 - mse: 0.2902 - mae: 0.4158\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3227 - mse: 0.3227 - mae: 0.4394\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2807 - mse: 0.2807 - mae: 0.4077\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b20l20:         mse       mae        r2\n",
      "0  0.322602  0.439988  0.537752\n",
      "Saved CNN evaluation results for b20l20 to: ../../data/evaluation_results/vae_blended_el_b20l20.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2780 - mse: 0.2780 - mae: 0.3972\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2574 - mse: 0.2574 - mae: 0.3782\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2652 - mse: 0.2652 - mae: 0.3863\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2546 - mse: 0.2546 - mae: 0.3768\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2741 - mse: 0.2741 - mae: 0.3954\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2848 - mse: 0.2848 - mae: 0.4027\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2751 - mse: 0.2751 - mae: 0.3982\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2463 - mse: 0.2463 - mae: 0.3659\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3057 - mse: 0.3057 - mae: 0.4176\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3083 - mse: 0.3083 - mae: 0.4234\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b24l3:         mse       mae       r2\n",
      "0  0.274937  0.394183  0.60605\n",
      "Saved CNN evaluation results for b24l3 to: ../../data/evaluation_results/vae_blended_el_b24l3.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2970 - mse: 0.2970 - mae: 0.4155\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2528 - mse: 0.2528 - mae: 0.3761\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2869 - mse: 0.2869 - mae: 0.4094\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3120 - mse: 0.3120 - mae: 0.4258\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2469 - mse: 0.2469 - mae: 0.3741\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2979 - mse: 0.2979 - mae: 0.4122\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2688 - mse: 0.2688 - mae: 0.3894\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2772 - mse: 0.2772 - mae: 0.4001\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2762 - mse: 0.2762 - mae: 0.3975\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2827 - mse: 0.2827 - mae: 0.4045\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b32l3:         mse      mae        r2\n",
      "0  0.279854  0.40045  0.599004\n",
      "Saved CNN evaluation results for b32l3 to: ../../data/evaluation_results/vae_blended_el_b32l3.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3079 - mse: 0.3079 - mae: 0.4431\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2964 - mse: 0.2964 - mae: 0.4191\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2921 - mse: 0.2921 - mae: 0.4193\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3281 - mse: 0.3281 - mae: 0.4441\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3550 - mse: 0.3550 - mae: 0.4652\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2620 - mse: 0.2620 - mae: 0.3884\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2674 - mse: 0.2674 - mae: 0.3958\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2798 - mse: 0.2798 - mae: 0.4056\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3100 - mse: 0.3100 - mae: 0.4287\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2622 - mse: 0.2622 - mae: 0.3925\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b32l5:        mse       mae        r2\n",
      "0  0.29608  0.420178  0.575755\n",
      "Saved CNN evaluation results for b32l5 to: ../../data/evaluation_results/vae_blended_el_b32l5.csv\n",
      "RUN: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3770 - mse: 0.3770 - mae: 0.4912\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3739 - mse: 0.3739 - mae: 0.4805\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3946 - mse: 0.3946 - mae: 0.4988\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3766 - mse: 0.3766 - mae: 0.4863\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3927 - mse: 0.3927 - mae: 0.4973\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3873 - mse: 0.3873 - mae: 0.4989\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4074 - mse: 0.4074 - mae: 0.5088\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4011 - mse: 0.4011 - mae: 0.5103\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3564 - mse: 0.3564 - mae: 0.4711\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3702 - mse: 0.3702 - mae: 0.4785\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b4e1000:         mse       mae        r2\n",
      "0  0.383714  0.492187  0.450186\n",
      "Saved CNN evaluation results for b4e1000 to: ../../data/evaluation_results/gan_blended_el_b4e1000.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3364 - mse: 0.3364 - mae: 0.4532\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3460 - mse: 0.3460 - mae: 0.4550\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3456 - mse: 0.3456 - mae: 0.4548\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3226 - mse: 0.3226 - mae: 0.4406\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3649 - mse: 0.3649 - mae: 0.4661\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2975 - mse: 0.2975 - mae: 0.4183\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3168 - mse: 0.3168 - mae: 0.4357\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3671 - mse: 0.3671 - mae: 0.4727\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3268 - mse: 0.3268 - mae: 0.4454\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3280 - mse: 0.3280 - mae: 0.4444\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b6e100:         mse       mae        r2\n",
      "0  0.335165  0.448621  0.519751\n",
      "Saved CNN evaluation results for b6e100 to: ../../data/evaluation_results/gan_blended_el_b6e100.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4323 - mse: 0.4323 - mae: 0.5265\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4398 - mse: 0.4398 - mae: 0.5287\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4231 - mse: 0.4231 - mae: 0.5184\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4547 - mse: 0.4547 - mae: 0.5393\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4521 - mse: 0.4521 - mae: 0.5448\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4535 - mse: 0.4535 - mae: 0.5415\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4444 - mse: 0.4444 - mae: 0.5356\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4336 - mse: 0.4336 - mae: 0.5276\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4369 - mse: 0.4369 - mae: 0.5257\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4385 - mse: 0.4385 - mae: 0.5309\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b8e500:         mse     mae        r2\n",
      "0  0.440889  0.5319  0.368262\n",
      "Saved CNN evaluation results for b8e500 to: ../../data/evaluation_results/gan_blended_el_b8e500.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4267 - mse: 0.4267 - mae: 0.5211\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4379 - mse: 0.4379 - mae: 0.5279\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4066 - mse: 0.4066 - mae: 0.5088\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4248 - mse: 0.4248 - mae: 0.5197\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4204 - mse: 0.4204 - mae: 0.5149\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3956 - mse: 0.3956 - mae: 0.4984\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4025 - mse: 0.4025 - mae: 0.5063\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4247 - mse: 0.4247 - mae: 0.5226\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3999 - mse: 0.3999 - mae: 0.5006\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4185 - mse: 0.4185 - mae: 0.5125\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b8e1000:         mse       mae        r2\n",
      "0  0.415755  0.513284  0.404276\n",
      "Saved CNN evaluation results for b8e1000 to: ../../data/evaluation_results/gan_blended_el_b8e1000.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3498 - mse: 0.3498 - mae: 0.4622\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3663 - mse: 0.3663 - mae: 0.4715\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3344 - mse: 0.3344 - mae: 0.4475\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3476 - mse: 0.3476 - mae: 0.4603\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3229 - mse: 0.3229 - mae: 0.4383\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3466 - mse: 0.3466 - mae: 0.4580\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3234 - mse: 0.3234 - mae: 0.4406\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3171 - mse: 0.3171 - mae: 0.4400\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2991 - mse: 0.2991 - mae: 0.4177\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3302 - mse: 0.3302 - mae: 0.4368\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b10e100:         mse       mae        r2\n",
      "0  0.333712  0.447303  0.521833\n",
      "Saved CNN evaluation results for b10e100 to: ../../data/evaluation_results/gan_blended_el_b10e100.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2979 - mse: 0.2979 - mae: 0.4181\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2935 - mse: 0.2935 - mae: 0.4131\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2502 - mse: 0.2502 - mae: 0.3867\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3294 - mse: 0.3294 - mae: 0.4453\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2577 - mse: 0.2577 - mae: 0.3785\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2808 - mse: 0.2808 - mae: 0.4078\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2778 - mse: 0.2778 - mae: 0.3964\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2813 - mse: 0.2813 - mae: 0.4047\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2893 - mse: 0.2893 - mae: 0.4065\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2858 - mse: 0.2858 - mae: 0.4081\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b12e100:         mse       mae        r2\n",
      "0  0.284387  0.406531  0.592509\n",
      "Saved CNN evaluation results for b12e100 to: ../../data/evaluation_results/gan_blended_el_b12e100.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2874 - mse: 0.2874 - mae: 0.4110\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3440 - mse: 0.3440 - mae: 0.4487\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3492 - mse: 0.3492 - mae: 0.4608\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2904 - mse: 0.2904 - mae: 0.4022\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2995 - mse: 0.2995 - mae: 0.4208\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2937 - mse: 0.2937 - mae: 0.4159\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2822 - mse: 0.2822 - mae: 0.4067\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3486 - mse: 0.3486 - mae: 0.4529\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2834 - mse: 0.2834 - mae: 0.4112\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3168 - mse: 0.3168 - mae: 0.4239\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b12e500:         mse       mae        r2\n",
      "0  0.309521  0.425403  0.556495\n",
      "Saved CNN evaluation results for b12e500 to: ../../data/evaluation_results/gan_blended_el_b12e500.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4221 - mse: 0.4221 - mae: 0.5209\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3966 - mse: 0.3966 - mae: 0.5035\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4220 - mse: 0.4220 - mae: 0.5225\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3981 - mse: 0.3981 - mae: 0.5018\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4131 - mse: 0.4131 - mae: 0.5114\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4169 - mse: 0.4169 - mae: 0.5143\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3872 - mse: 0.3872 - mae: 0.4910\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3849 - mse: 0.3849 - mae: 0.4872\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3924 - mse: 0.3924 - mae: 0.4936\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3913 - mse: 0.3913 - mae: 0.4917\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b16e500:         mse       mae        r2\n",
      "0  0.402478  0.503786  0.423301\n",
      "Saved CNN evaluation results for b16e500 to: ../../data/evaluation_results/gan_blended_el_b16e500.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3295 - mse: 0.3295 - mae: 0.4473\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3589 - mse: 0.3589 - mae: 0.4702\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3214 - mse: 0.3214 - mae: 0.4402\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3397 - mse: 0.3397 - mae: 0.4548\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3299 - mse: 0.3299 - mae: 0.4424\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3215 - mse: 0.3215 - mae: 0.4397\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3611 - mse: 0.3611 - mae: 0.4759\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3001 - mse: 0.3001 - mae: 0.4287\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3222 - mse: 0.3222 - mae: 0.4390\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3125 - mse: 0.3125 - mae: 0.4361\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b20e500:        mse       mae       r2\n",
      "0  0.32968  0.447434  0.52761\n",
      "Saved CNN evaluation results for b20e500 to: ../../data/evaluation_results/gan_blended_el_b20e500.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3978 - mse: 0.3978 - mae: 0.5029\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3726 - mse: 0.3726 - mae: 0.4833\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3942 - mse: 0.3942 - mae: 0.4947\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3960 - mse: 0.3960 - mae: 0.4984\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3926 - mse: 0.3926 - mae: 0.4930\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4031 - mse: 0.4031 - mae: 0.5055\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3662 - mse: 0.3662 - mae: 0.4771\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3948 - mse: 0.3948 - mae: 0.4972\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3770 - mse: 0.3770 - mae: 0.4846\n",
      "4/4 [==============================] - 1s 3ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3916 - mse: 0.3916 - mae: 0.4956\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b24e1000:        mse       mae      r2\n",
      "0  0.38859  0.493221  0.4432\n",
      "Saved CNN evaluation results for b24e1000 to: ../../data/evaluation_results/gan_blended_el_b24e1000.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4047 - mse: 0.4047 - mae: 0.5089\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4319 - mse: 0.4319 - mae: 0.5294\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4017 - mse: 0.4017 - mae: 0.5039\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3999 - mse: 0.3999 - mae: 0.5075\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4181 - mse: 0.4181 - mae: 0.5211\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4163 - mse: 0.4163 - mae: 0.5147\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4158 - mse: 0.4158 - mae: 0.5116\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3949 - mse: 0.3949 - mae: 0.5013\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4246 - mse: 0.4246 - mae: 0.5208\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4182 - mse: 0.4182 - mae: 0.5197\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b32e1000:         mse       mae        r2\n",
      "0  0.412594  0.513886  0.408805\n",
      "Saved CNN evaluation results for b32e1000 to: ../../data/evaluation_results/gan_blended_el_b32e1000.csv\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_save_cnn_blended(el_vae_data, 'vae', 1)\n",
    "evaluate_and_save_cnn_blended(el_gan_data, 'gan', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c44349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4935f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 14:43:34.631326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6922 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1\n",
      "2024-04-10 14:43:43.904382: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-04-10 14:43:53.575941: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f79bd645f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-10 14:43:53.575983: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2024-04-10 14:43:53.580425: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712756633.683699  728686 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0904 - mse: 0.0904 - mae: 0.2189\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0970 - mse: 0.0970 - mae: 0.2267\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0999 - mse: 0.0999 - mae: 0.2298\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1034 - mse: 0.1034 - mae: 0.2250\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0916 - mse: 0.0916 - mae: 0.2208\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1014 - mse: 0.1014 - mae: 0.2324\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0952 - mse: 0.0952 - mae: 0.2262\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0978 - mse: 0.0978 - mae: 0.2254\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0934 - mse: 0.0934 - mae: 0.2232\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2150\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 10\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0966 - mse: 0.0966 - mae: 0.2265\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 11\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1002 - mse: 0.1002 - mae: 0.2303\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 12\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1043 - mse: 0.1043 - mae: 0.2356\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 13\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0821 - mse: 0.0821 - mae: 0.2067\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 14\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0951 - mse: 0.0951 - mae: 0.2216\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 15\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0924 - mse: 0.0924 - mae: 0.2189\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 16\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0944 - mse: 0.0944 - mae: 0.2202\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 17\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0907 - mse: 0.0907 - mae: 0.2171\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 18\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0937 - mse: 0.0937 - mae: 0.2365\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 19\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0903 - mse: 0.0903 - mae: 0.2210\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 20\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0863 - mse: 0.0863 - mae: 0.2155\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 21\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0768 - mse: 0.0768 - mae: 0.1981\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 22\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0971 - mse: 0.0971 - mae: 0.2267\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 23\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0885 - mse: 0.0885 - mae: 0.2201\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 24\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1040 - mse: 0.1040 - mae: 0.2312\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 25\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0960 - mse: 0.0960 - mae: 0.2273\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 26\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0937 - mse: 0.0937 - mae: 0.2181\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 27\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0910 - mse: 0.0910 - mae: 0.2145\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "RUN: 28\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0894 - mse: 0.0894 - mae: 0.2109\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 29\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0964 - mse: 0.0964 - mae: 0.2253\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 30\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0863 - mse: 0.0863 - mae: 0.2135\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 31\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0948 - mse: 0.0948 - mae: 0.2241\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 32\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0915 - mse: 0.0915 - mae: 0.2184\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 33\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0958 - mse: 0.0958 - mae: 0.2325\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 34\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0854 - mse: 0.0854 - mae: 0.2133\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 35\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0952 - mse: 0.0952 - mae: 0.2289\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 36\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0947 - mse: 0.0947 - mae: 0.2243\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 37\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0826 - mse: 0.0826 - mae: 0.2102\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 38\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0956 - mse: 0.0956 - mae: 0.2223\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 39\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0854 - mse: 0.0854 - mae: 0.2142\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 40\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0841 - mse: 0.0841 - mae: 0.2078\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 41\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0929 - mse: 0.0929 - mae: 0.2281\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 42\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0859 - mse: 0.0859 - mae: 0.2153\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 43\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0865 - mse: 0.0865 - mae: 0.2091\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 44\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0836 - mse: 0.0836 - mae: 0.2111\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 45\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0960 - mse: 0.0960 - mae: 0.2281\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 46\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0944 - mse: 0.0944 - mae: 0.2279\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 47\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0863 - mse: 0.0863 - mae: 0.2138\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 48\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0923 - mse: 0.0923 - mae: 0.2272\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 49\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0965 - mse: 0.0965 - mae: 0.2241\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 50\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0918 - mse: 0.0918 - mae: 0.2166\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 51\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0941 - mse: 0.0941 - mae: 0.2188\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 52\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0923 - mse: 0.0923 - mae: 0.2234\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 53\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0997 - mse: 0.0997 - mae: 0.2294\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 54\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2158\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 55\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1096 - mse: 0.1096 - mae: 0.2380\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 56\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0931 - mse: 0.0931 - mae: 0.2205\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 57\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0934 - mse: 0.0934 - mae: 0.2256\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 58\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0871 - mse: 0.0871 - mae: 0.2157\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 59\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0990 - mse: 0.0990 - mae: 0.2228\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 60\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0910 - mse: 0.0910 - mae: 0.2177\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 61\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0871 - mse: 0.0871 - mae: 0.2151\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 62\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0965 - mse: 0.0965 - mae: 0.2316\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 63\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0900 - mse: 0.0900 - mae: 0.2102\n",
      "4/4 [==============================] - 1s 2ms/step\n",
      "RUN: 64\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0907 - mse: 0.0907 - mae: 0.2173\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 65\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0925 - mse: 0.0925 - mae: 0.2199\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 66\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0930 - mse: 0.0930 - mae: 0.2219\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 67\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0802 - mse: 0.0802 - mae: 0.2087\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 68\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0881 - mse: 0.0881 - mae: 0.2192\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 69\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0905 - mse: 0.0905 - mae: 0.2116\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 70\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0847 - mse: 0.0847 - mae: 0.2186\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 71\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0927 - mse: 0.0927 - mae: 0.2262\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 72\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0959 - mse: 0.0959 - mae: 0.2245\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 73\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0897 - mse: 0.0897 - mae: 0.2171\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 74\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0828 - mse: 0.0828 - mae: 0.2053\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 75\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0940 - mse: 0.0940 - mae: 0.2225\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 76\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1011 - mse: 0.1011 - mae: 0.2395\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 77\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0859 - mse: 0.0859 - mae: 0.2118\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 78\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0924 - mse: 0.0924 - mae: 0.2163\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 79\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0904 - mse: 0.0904 - mae: 0.2168\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 80\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0922 - mse: 0.0922 - mae: 0.2215\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 81\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0893 - mse: 0.0893 - mae: 0.2226\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 82\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0904 - mse: 0.0904 - mae: 0.2192\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 83\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0865 - mse: 0.0865 - mae: 0.2137\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 84\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0910 - mse: 0.0910 - mae: 0.2217\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 85\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0944 - mse: 0.0944 - mae: 0.2230\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 86\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0926 - mse: 0.0926 - mae: 0.2193\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 87\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0856 - mse: 0.0856 - mae: 0.2151\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 88\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0849 - mse: 0.0849 - mae: 0.2121\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 89\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0968 - mse: 0.0968 - mae: 0.2307\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 90\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0884 - mse: 0.0884 - mae: 0.2194\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 91\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0891 - mse: 0.0891 - mae: 0.2187\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 92\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0853 - mse: 0.0853 - mae: 0.2073\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 93\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0941 - mse: 0.0941 - mae: 0.2209\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 94\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0927 - mse: 0.0927 - mae: 0.2213\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 95\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0842 - mse: 0.0842 - mae: 0.2084\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 96\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0906 - mse: 0.0906 - mae: 0.2185\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 97\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0809 - mse: 0.0809 - mae: 0.2072\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 98\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0975 - mse: 0.0975 - mae: 0.2293\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 99\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0871 - mse: 0.0871 - mae: 0.2094\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b8l15:        mse     mae      r2\n",
      "0   0.0904  0.2189  0.4926\n",
      "1   0.0970  0.2267  0.4553\n",
      "2   0.0999  0.2298  0.4395\n",
      "3   0.1034  0.2250  0.4197\n",
      "4   0.0916  0.2208  0.4859\n",
      "..     ...     ...     ...\n",
      "95  0.0842  0.2084  0.5273\n",
      "96  0.0906  0.2185  0.4912\n",
      "97  0.0809  0.2072  0.5458\n",
      "98  0.0975  0.2293  0.4528\n",
      "99  0.0871  0.2094  0.5109\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "Saved CNN evaluation results for b8l15 to: ../../data/evaluation_results/vae_blended_th_b8l15.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1038 - mse: 0.1038 - mae: 0.2360\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1059 - mse: 0.1059 - mae: 0.2355\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1048 - mse: 0.1048 - mae: 0.2351\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1013 - mse: 0.1013 - mae: 0.2345\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1044 - mse: 0.1044 - mae: 0.2336\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1012 - mse: 0.1012 - mae: 0.2260\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1049 - mse: 0.1049 - mae: 0.2403\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1045 - mse: 0.1045 - mae: 0.2294\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1040 - mse: 0.1040 - mae: 0.2393\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1064 - mse: 0.1064 - mae: 0.2350\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1022 - mse: 0.1022 - mae: 0.2356\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 11\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1034 - mse: 0.1034 - mae: 0.2376\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 12\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1068 - mse: 0.1068 - mae: 0.2390\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 13\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1064 - mse: 0.1064 - mae: 0.2339\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 14\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1061 - mse: 0.1061 - mae: 0.2366\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 15\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1101 - mse: 0.1101 - mae: 0.2460\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 16\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1007 - mse: 0.1007 - mae: 0.2333\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 17\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1055 - mse: 0.1055 - mae: 0.2402\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 18\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0986 - mse: 0.0986 - mae: 0.2255\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 19\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1002 - mse: 0.1002 - mae: 0.2239\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1073 - mse: 0.1073 - mae: 0.2326\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 21\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1089 - mse: 0.1089 - mae: 0.2439\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 22\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0990 - mse: 0.0990 - mae: 0.2287\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 23\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1009 - mse: 0.1009 - mae: 0.2301\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 24\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1010 - mse: 0.1010 - mae: 0.2298\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 25\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1010 - mse: 0.1010 - mae: 0.2335\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 26\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1096 - mse: 0.1096 - mae: 0.2438\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 27\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1038 - mse: 0.1038 - mae: 0.2449\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 28\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1070 - mse: 0.1070 - mae: 0.2350\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 29\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1047 - mse: 0.1047 - mae: 0.2395\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1027 - mse: 0.1027 - mae: 0.2314\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 31\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0971 - mse: 0.0971 - mae: 0.2198\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 32\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1019 - mse: 0.1019 - mae: 0.2367\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 33\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0953 - mse: 0.0953 - mae: 0.2229\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 34\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1025 - mse: 0.1025 - mae: 0.2377\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 35\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0996 - mse: 0.0996 - mae: 0.2244\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 36\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1062 - mse: 0.1062 - mae: 0.2405\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 37\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1015 - mse: 0.1015 - mae: 0.2277\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 38\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1050 - mse: 0.1050 - mae: 0.2384\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 39\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1025 - mse: 0.1025 - mae: 0.2284\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1039 - mse: 0.1039 - mae: 0.2341\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 41\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1109 - mse: 0.1109 - mae: 0.2442\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 42\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1028 - mse: 0.1028 - mae: 0.2373\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 43\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1028 - mse: 0.1028 - mae: 0.2308\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 44\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0976 - mse: 0.0976 - mae: 0.2235\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 45\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0999 - mse: 0.0999 - mae: 0.2283\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 46\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0981 - mse: 0.0981 - mae: 0.2260\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 47\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1061 - mse: 0.1061 - mae: 0.2416\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 48\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1048 - mse: 0.1048 - mae: 0.2340\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 49\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1017 - mse: 0.1017 - mae: 0.2330\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 50\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1030 - mse: 0.1030 - mae: 0.2374\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 51\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0985 - mse: 0.0985 - mae: 0.2277\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 52\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0977 - mse: 0.0977 - mae: 0.2344\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 53\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1003 - mse: 0.1003 - mae: 0.2293\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 54\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1070 - mse: 0.1070 - mae: 0.2323\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 55\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1000 - mse: 0.1000 - mae: 0.2305\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 56\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0999 - mse: 0.0999 - mae: 0.2305\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 57\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0985 - mse: 0.0985 - mae: 0.2292\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 58\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1061 - mse: 0.1061 - mae: 0.2392\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 59\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1061 - mse: 0.1061 - mae: 0.2355\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1075 - mse: 0.1075 - mae: 0.2447\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 61\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0994 - mse: 0.0994 - mae: 0.2251\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 62\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1051 - mse: 0.1051 - mae: 0.2360\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 63\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0992 - mse: 0.0992 - mae: 0.2293\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 64\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1035 - mse: 0.1035 - mae: 0.2344\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 65\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1033 - mse: 0.1033 - mae: 0.2296\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 66\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1043 - mse: 0.1043 - mae: 0.2384\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 67\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1012 - mse: 0.1012 - mae: 0.2322\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 68\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1022 - mse: 0.1022 - mae: 0.2291\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 69\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1049 - mse: 0.1049 - mae: 0.2392\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 70\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0972 - mse: 0.0972 - mae: 0.2243\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 71\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0985 - mse: 0.0985 - mae: 0.2227\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 72\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0998 - mse: 0.0998 - mae: 0.2230\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 73\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1065 - mse: 0.1065 - mae: 0.2386\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 74\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1031 - mse: 0.1031 - mae: 0.2318\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1033 - mse: 0.1033 - mae: 0.2317\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 76\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1019 - mse: 0.1019 - mae: 0.2355\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 77\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1008 - mse: 0.1008 - mae: 0.2337\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 78\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1027 - mse: 0.1027 - mae: 0.2360\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 79\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1000 - mse: 0.1000 - mae: 0.2291\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 80\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0962 - mse: 0.0962 - mae: 0.2229\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 81\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1029 - mse: 0.1029 - mae: 0.2281\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 82\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1020 - mse: 0.1020 - mae: 0.2341\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 83\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1065 - mse: 0.1065 - mae: 0.2331\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 84\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1049 - mse: 0.1049 - mae: 0.2342\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 85\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1024 - mse: 0.1024 - mae: 0.2314\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 86\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0977 - mse: 0.0977 - mae: 0.2240\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 87\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1027 - mse: 0.1027 - mae: 0.2249\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 88\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1032 - mse: 0.1032 - mae: 0.2292\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 89\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1028 - mse: 0.1028 - mae: 0.2350\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 90\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1044 - mse: 0.1044 - mae: 0.2381\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 91\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1008 - mse: 0.1008 - mae: 0.2335\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 92\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1038 - mse: 0.1038 - mae: 0.2398\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 93\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1072 - mse: 0.1072 - mae: 0.2373\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 94\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0983 - mse: 0.0983 - mae: 0.2300\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 95\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1004 - mse: 0.1004 - mae: 0.2240\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 96\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1061 - mse: 0.1061 - mae: 0.2411\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 97\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1050 - mse: 0.1050 - mae: 0.2382\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 98\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1042 - mse: 0.1042 - mae: 0.2329\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 99\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0978 - mse: 0.0978 - mae: 0.2259\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b8e1000:        mse     mae      r2\n",
      "0   0.1038  0.2360  0.4172\n",
      "1   0.1059  0.2355  0.4056\n",
      "2   0.1048  0.2351  0.4119\n",
      "3   0.1013  0.2345  0.4314\n",
      "4   0.1044  0.2336  0.4138\n",
      "..     ...     ...     ...\n",
      "95  0.1004  0.2240  0.4363\n",
      "96  0.1061  0.2411  0.4047\n",
      "97  0.1050  0.2382  0.4105\n",
      "98  0.1042  0.2329  0.4153\n",
      "99  0.0978  0.2259  0.4513\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "Saved CNN evaluation results for b8e1000 to: ../../data/evaluation_results/gan_blended_th_b8e1000.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 52: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1278 - mse: 0.1278 - mae: 0.2640\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Restoring model weights from the end of the best epoch: 81.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 91: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1422 - mse: 0.1422 - mae: 0.2804\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 63: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1198 - mse: 0.1198 - mae: 0.2506\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 83: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1248 - mse: 0.1248 - mae: 0.2570\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 79: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1222 - mse: 0.1222 - mae: 0.2550\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 87: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1291 - mse: 0.1291 - mae: 0.2701\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 77.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 87: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1212 - mse: 0.1212 - mae: 0.2468\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 34: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1490 - mse: 0.1490 - mae: 0.3101\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 77: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1150 - mse: 0.1150 - mae: 0.2427\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 54: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1321 - mse: 0.1321 - mae: 0.2588\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 10\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1221 - mse: 0.1221 - mae: 0.2536\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 11\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 77: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1205 - mse: 0.1205 - mae: 0.2530\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 12\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Epoch 77: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1266 - mse: 0.1266 - mae: 0.2609\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 13\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1191 - mse: 0.1191 - mae: 0.2514\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 14\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 49: early stopping\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1351 - mse: 0.1351 - mae: 0.2732\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 15\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 57: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1258 - mse: 0.1258 - mae: 0.2458\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 16\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 75: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1170 - mse: 0.1170 - mae: 0.2504\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 17\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 87: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1107 - mse: 0.1107 - mae: 0.2396\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 18\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 58: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1377 - mse: 0.1377 - mae: 0.2658\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 19\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 25.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 35: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1399 - mse: 0.1399 - mae: 0.2729\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 20\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 85: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1345 - mse: 0.1345 - mae: 0.2722\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 21\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 66: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1294 - mse: 0.1294 - mae: 0.2626\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 22\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 90: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1250 - mse: 0.1250 - mae: 0.2598\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 23\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 99: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1362 - mse: 0.1362 - mae: 0.2711\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 24\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "Epoch 84: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1256 - mse: 0.1256 - mae: 0.2594\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 25\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 71: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1161 - mse: 0.1161 - mae: 0.2415\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 26\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "Epoch 88: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1145 - mse: 0.1145 - mae: 0.2431\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 27\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 51: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1284 - mse: 0.1284 - mae: 0.2493\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 28\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 80: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1268 - mse: 0.1268 - mae: 0.2622\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 29\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 68: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1241 - mse: 0.1241 - mae: 0.2598\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 30\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 72: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1187 - mse: 0.1187 - mae: 0.2351\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 31\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 77: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1341 - mse: 0.1341 - mae: 0.2717\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 32\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 69: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1172 - mse: 0.1172 - mae: 0.2478\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 33\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1158 - mse: 0.1158 - mae: 0.2453\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 34\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 75: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1299 - mse: 0.1299 - mae: 0.2634\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 35\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 64: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1262 - mse: 0.1262 - mae: 0.2592\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 36\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 99: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1236 - mse: 0.1236 - mae: 0.2609\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 37\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 65: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1198 - mse: 0.1198 - mae: 0.2415\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 38\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1231 - mse: 0.1231 - mae: 0.2564\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 39\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 79: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1307 - mse: 0.1307 - mae: 0.2694\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 40\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 18: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1756 - mse: 0.1756 - mae: 0.3119\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 41\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 53: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1321 - mse: 0.1321 - mae: 0.2669\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 42\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 83.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 93: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1225 - mse: 0.1225 - mae: 0.2550\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 43\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 90: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1125 - mse: 0.1125 - mae: 0.2421\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 44\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 65: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1177 - mse: 0.1177 - mae: 0.2457\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 45\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 71: early stopping\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1340 - mse: 0.1340 - mae: 0.2754\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 46\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 100: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1284 - mse: 0.1284 - mae: 0.2652\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 47\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 36: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1435 - mse: 0.1435 - mae: 0.3008\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 48\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 65: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1189 - mse: 0.1189 - mae: 0.2480\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 49\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Restoring model weights from the end of the best epoch: 80.\n",
      "Epoch 90: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1144 - mse: 0.1144 - mae: 0.2440\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 50\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 70: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1280 - mse: 0.1280 - mae: 0.2661\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 51\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 83: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1211 - mse: 0.1211 - mae: 0.2535\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 52\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 65: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1203 - mse: 0.1203 - mae: 0.2438\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 53\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 62: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1230 - mse: 0.1230 - mae: 0.2591\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 54\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 70: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1363 - mse: 0.1363 - mae: 0.2735\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 55\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 87: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1280 - mse: 0.1280 - mae: 0.2608\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 56\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Restoring model weights from the end of the best epoch: 90.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 100: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1248 - mse: 0.1248 - mae: 0.2599\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 57\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 84: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1130 - mse: 0.1130 - mae: 0.2457\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 58\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 88: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1266 - mse: 0.1266 - mae: 0.2607\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 59\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 83.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 93: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1265 - mse: 0.1265 - mae: 0.2548\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 60\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 58: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1247 - mse: 0.1247 - mae: 0.2517\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 61\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 76: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1339 - mse: 0.1339 - mae: 0.2683\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 62\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 57: early stopping\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1418 - mse: 0.1418 - mae: 0.2772\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 63\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 72: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1230 - mse: 0.1230 - mae: 0.2696\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 64\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 62: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1620 - mse: 0.1620 - mae: 0.3043\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 65\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 47.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 57: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1419 - mse: 0.1419 - mae: 0.2877\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 66\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 62: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1337 - mse: 0.1337 - mae: 0.2681\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 67\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 50: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1287 - mse: 0.1287 - mae: 0.2690\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 68\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 75: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1301 - mse: 0.1301 - mae: 0.2666\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 69\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1142 - mse: 0.1142 - mae: 0.2413\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 70\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 63: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1384 - mse: 0.1384 - mae: 0.2783\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 71\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1274 - mse: 0.1274 - mae: 0.2599\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 72\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 72.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 82: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1227 - mse: 0.1227 - mae: 0.2527\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 73\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 58: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1319 - mse: 0.1319 - mae: 0.2707\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 74\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1321 - mse: 0.1321 - mae: 0.2678\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 75\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 79: early stopping\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1319 - mse: 0.1319 - mae: 0.2706\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 76\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 77: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1316 - mse: 0.1316 - mae: 0.2598\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 77\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 85: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1228 - mse: 0.1228 - mae: 0.2531\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 78\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "Epoch 77: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1287 - mse: 0.1287 - mae: 0.2604\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 79\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 74.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 84: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1283 - mse: 0.1283 - mae: 0.2641\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 80\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 66: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1200 - mse: 0.1200 - mae: 0.2682\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 81\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 40: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1367 - mse: 0.1367 - mae: 0.2890\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 82\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 37: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1275 - mse: 0.1275 - mae: 0.2518\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 83\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1256 - mse: 0.1256 - mae: 0.2557\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 84\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 76.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 86: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1238 - mse: 0.1238 - mae: 0.2531\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 85\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 72: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1385 - mse: 0.1385 - mae: 0.2778\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 86\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 77: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1301 - mse: 0.1301 - mae: 0.2636\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 87\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 67: early stopping\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1232 - mse: 0.1232 - mae: 0.2528\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 88\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1224 - mse: 0.1224 - mae: 0.2524\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 89\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 63: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1304 - mse: 0.1304 - mae: 0.2650\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 90\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 88: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1146 - mse: 0.1146 - mae: 0.2434\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 91\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 70: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1393 - mse: 0.1393 - mae: 0.2772\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 92\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 65: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1266 - mse: 0.1266 - mae: 0.2566\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 93\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 76: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1151 - mse: 0.1151 - mae: 0.2438\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 94\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 88: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1321 - mse: 0.1321 - mae: 0.2640\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 95\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 58: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1328 - mse: 0.1328 - mae: 0.2731\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 96\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 88: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1318 - mse: 0.1318 - mae: 0.2721\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 97\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 67: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1186 - mse: 0.1186 - mae: 0.2473\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 98\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 68: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1254 - mse: 0.1254 - mae: 0.2612\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 99\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 54.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 64: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1346 - mse: 0.1346 - mae: 0.2765\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b32e100:        mse     mae      r2\n",
      "0   0.1278  0.2640  0.2827\n",
      "1   0.1422  0.2804  0.2020\n",
      "2   0.1198  0.2506  0.3277\n",
      "3   0.1248  0.2570  0.2993\n",
      "4   0.1222  0.2550  0.3144\n",
      "..     ...     ...     ...\n",
      "95  0.1328  0.2731  0.2546\n",
      "96  0.1318  0.2721  0.2605\n",
      "97  0.1186  0.2473  0.3343\n",
      "98  0.1254  0.2612  0.2964\n",
      "99  0.1346  0.2765  0.2446\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "Saved CNN evaluation results for b32e100 to: ../../data/evaluation_results/gan_blended_th_b32e100.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4580 - mse: 0.4580 - mae: 0.5529\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4451 - mse: 0.4451 - mae: 0.5427\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4524 - mse: 0.4524 - mae: 0.5445\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4382 - mse: 0.4382 - mae: 0.5320\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4530 - mse: 0.4530 - mae: 0.5487\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4543 - mse: 0.4543 - mae: 0.5560\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4626 - mse: 0.4626 - mae: 0.5564\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4473 - mse: 0.4473 - mae: 0.5368\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4595 - mse: 0.4595 - mae: 0.5563\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4364 - mse: 0.4364 - mae: 0.5296\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4359 - mse: 0.4359 - mae: 0.5305\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 11\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4477 - mse: 0.4477 - mae: 0.5413\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 12\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4484 - mse: 0.4484 - mae: 0.5388\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 13\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4591 - mse: 0.4591 - mae: 0.5491\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 14\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4632 - mse: 0.4632 - mae: 0.5535\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 15\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4558 - mse: 0.4558 - mae: 0.5533\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 16\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4793 - mse: 0.4793 - mae: 0.5642\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 17\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4559 - mse: 0.4559 - mae: 0.5483\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 18\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4401 - mse: 0.4401 - mae: 0.5363\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 19\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4544 - mse: 0.4544 - mae: 0.5464\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4449 - mse: 0.4449 - mae: 0.5354\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 21\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4504 - mse: 0.4504 - mae: 0.5429\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 22\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4547 - mse: 0.4547 - mae: 0.5477\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 23\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4355 - mse: 0.4355 - mae: 0.5294\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 24\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4509 - mse: 0.4509 - mae: 0.5517\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 25\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4333 - mse: 0.4333 - mae: 0.5328\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 26\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.4586 - mae: 0.5464\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 27\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4518 - mse: 0.4518 - mae: 0.5428\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 28\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4898 - mse: 0.4898 - mae: 0.5775\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 29\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4444 - mse: 0.4444 - mae: 0.5366\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5015 - mse: 0.5015 - mae: 0.5871\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 31\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4605 - mse: 0.4605 - mae: 0.5493\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 32\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4410 - mse: 0.4410 - mae: 0.5381\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 33\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4498 - mse: 0.4498 - mae: 0.5454\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 34\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4471 - mse: 0.4471 - mae: 0.5384\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 35\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4471 - mse: 0.4471 - mae: 0.5407\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 36\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4479 - mse: 0.4479 - mae: 0.5452\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 37\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4591 - mse: 0.4591 - mae: 0.5537\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 38\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4540 - mse: 0.4540 - mae: 0.5485\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 39\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4432 - mse: 0.4432 - mae: 0.5378\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 40\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4508 - mse: 0.4508 - mae: 0.5462\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 41\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4429 - mse: 0.4429 - mae: 0.5379\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 42\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4499 - mse: 0.4499 - mae: 0.5422\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 43\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4586 - mse: 0.4586 - mae: 0.5457\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 44\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4473 - mse: 0.4473 - mae: 0.5440\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4363 - mse: 0.4363 - mae: 0.5336\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 46\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4273 - mse: 0.4273 - mae: 0.5258\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 47\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4576 - mse: 0.4576 - mae: 0.5488\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 48\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4541 - mse: 0.4541 - mae: 0.5481\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 49\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4483 - mse: 0.4483 - mae: 0.5378\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4454 - mse: 0.4454 - mae: 0.5384\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 51\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4609 - mse: 0.4609 - mae: 0.5588\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 52\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4499 - mse: 0.4499 - mae: 0.5408\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 53\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4688 - mse: 0.4688 - mae: 0.5639\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 54\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4550 - mse: 0.4550 - mae: 0.5516\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 55\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4735 - mse: 0.4735 - mae: 0.5695\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 56\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4433 - mse: 0.4433 - mae: 0.5334\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 57\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4656 - mse: 0.4656 - mae: 0.5560\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 58\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4372 - mse: 0.4372 - mae: 0.5324\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 59\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4516 - mse: 0.4516 - mae: 0.5535\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4428 - mse: 0.4428 - mae: 0.5372\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 61\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4600 - mse: 0.4600 - mae: 0.5544\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 62\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4590 - mse: 0.4590 - mae: 0.5557\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 63\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4437 - mse: 0.4437 - mae: 0.5335\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 64\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4450 - mse: 0.4450 - mae: 0.5392\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 65\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4450 - mse: 0.4450 - mae: 0.5321\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 66\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4393 - mse: 0.4393 - mae: 0.5345\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 67\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4323 - mse: 0.4323 - mae: 0.5298\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 68\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4562 - mse: 0.4562 - mae: 0.5505\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 69\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4546 - mse: 0.4546 - mae: 0.5492\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 70\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4604 - mse: 0.4604 - mae: 0.5566\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 71\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4552 - mse: 0.4552 - mae: 0.5499\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 72\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4301 - mse: 0.4301 - mae: 0.5242\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 73\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4589 - mse: 0.4589 - mae: 0.5487\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 74\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4445 - mse: 0.4445 - mae: 0.5412\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4627 - mse: 0.4627 - mae: 0.5563\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 76\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4457 - mse: 0.4457 - mae: 0.5385\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 77\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4630 - mse: 0.4630 - mae: 0.5584\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 78\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4417 - mse: 0.4417 - mae: 0.5368\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 79\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4481 - mse: 0.4481 - mae: 0.5440\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 80\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4534 - mse: 0.4534 - mae: 0.5461\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 81\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4542 - mse: 0.4542 - mae: 0.5410\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 82\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4492 - mse: 0.4492 - mae: 0.5411\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 83\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4468 - mse: 0.4468 - mae: 0.5375\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 84\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4474 - mse: 0.4474 - mae: 0.5367\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 85\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4622 - mse: 0.4622 - mae: 0.5533\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 86\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4516 - mse: 0.4516 - mae: 0.5425\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 87\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4335 - mse: 0.4335 - mae: 0.5294\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 88\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4518 - mse: 0.4518 - mae: 0.5432\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 89\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4568 - mse: 0.4568 - mae: 0.5471\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 90\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4393 - mse: 0.4393 - mae: 0.5348\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 91\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4747 - mse: 0.4747 - mae: 0.5537\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 92\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4335 - mse: 0.4335 - mae: 0.5268\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 93\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4494 - mse: 0.4494 - mae: 0.5410\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 94\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4575 - mse: 0.4575 - mae: 0.5441\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 95\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4561 - mse: 0.4561 - mae: 0.5483\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 96\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4405 - mse: 0.4405 - mae: 0.5330\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 97\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4280 - mse: 0.4280 - mae: 0.5259\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 98\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4341 - mse: 0.4341 - mae: 0.5322\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 99\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4405 - mse: 0.4405 - mae: 0.5348\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b8l10:        mse     mae      r2\n",
      "0   0.4580  0.5529  0.3438\n",
      "1   0.4451  0.5427  0.3623\n",
      "2   0.4524  0.5445  0.3518\n",
      "3   0.4382  0.5320  0.3721\n",
      "4   0.4530  0.5487  0.3509\n",
      "..     ...     ...     ...\n",
      "95  0.4561  0.5483  0.3465\n",
      "96  0.4405  0.5330  0.3688\n",
      "97  0.4280  0.5259  0.3868\n",
      "98  0.4341  0.5322  0.3779\n",
      "99  0.4405  0.5348  0.3689\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "Saved CNN evaluation results for b8l10 to: ../../data/evaluation_results/vae_el_b8l10.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4867 - mse: 0.4867 - mae: 0.5515\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4571 - mse: 0.4571 - mae: 0.5195\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4444 - mse: 0.4444 - mae: 0.5152\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4552 - mse: 0.4552 - mae: 0.5209\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4297 - mse: 0.4297 - mae: 0.5058\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4355 - mse: 0.4355 - mae: 0.5079\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4521 - mse: 0.4521 - mae: 0.5174\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4478 - mse: 0.4478 - mae: 0.5137\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4544 - mse: 0.4544 - mae: 0.5218\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4530 - mse: 0.4530 - mae: 0.5168\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4490 - mse: 0.4490 - mae: 0.5054\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 11\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4518 - mse: 0.4518 - mae: 0.5124\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 12\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4528 - mse: 0.4528 - mae: 0.5276\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 13\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4686 - mse: 0.4686 - mae: 0.5412\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 14\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4385 - mse: 0.4385 - mae: 0.5064\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 15\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4232 - mse: 0.4232 - mae: 0.4951\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 16\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4485 - mse: 0.4485 - mae: 0.5095\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 17\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4321 - mse: 0.4321 - mae: 0.5041\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 18\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4380 - mse: 0.4380 - mae: 0.5139\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 19\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4326 - mse: 0.4326 - mae: 0.4978\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4568 - mse: 0.4568 - mae: 0.5188\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 21\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4459 - mse: 0.4459 - mae: 0.5127\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 22\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4563 - mse: 0.4563 - mae: 0.5246\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 23\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4550 - mse: 0.4550 - mae: 0.5181\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 24\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4748 - mse: 0.4748 - mae: 0.5324\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 25\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4684 - mse: 0.4684 - mae: 0.5363\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 26\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4736 - mse: 0.4736 - mae: 0.5336\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 27\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4876 - mse: 0.4876 - mae: 0.5460\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 28\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4537 - mse: 0.4537 - mae: 0.5178\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 29\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4600 - mse: 0.4600 - mae: 0.5251\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4531 - mse: 0.4531 - mae: 0.5200\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 31\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4453 - mse: 0.4453 - mae: 0.5090\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 32\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4553 - mse: 0.4553 - mae: 0.5129\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 33\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4475 - mse: 0.4475 - mae: 0.5076\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 34\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4630 - mse: 0.4630 - mae: 0.5245\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 35\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4985 - mse: 0.4985 - mae: 0.5583\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 36\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4577 - mse: 0.4577 - mae: 0.5226\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 37\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4449 - mse: 0.4449 - mae: 0.5242\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 38\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4720 - mse: 0.4720 - mae: 0.5412\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 39\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4277 - mse: 0.4277 - mae: 0.4941\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4392 - mse: 0.4392 - mae: 0.5089\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 41\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4540 - mse: 0.4540 - mae: 0.5176\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 42\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4231 - mse: 0.4231 - mae: 0.5017\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 43\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4623 - mse: 0.4623 - mae: 0.5255\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 44\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4305 - mse: 0.4305 - mae: 0.4985\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 45\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4546 - mse: 0.4546 - mae: 0.5166\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 46\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4572 - mse: 0.4572 - mae: 0.5277\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 47\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4279 - mse: 0.4279 - mae: 0.4944\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 48\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4546 - mse: 0.4546 - mae: 0.5184\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 49\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4531 - mse: 0.4531 - mae: 0.5230\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4589 - mse: 0.4589 - mae: 0.5184\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 51\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4581 - mse: 0.4581 - mae: 0.5260\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 52\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4680 - mse: 0.4680 - mae: 0.5342\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 53\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4415 - mse: 0.4415 - mae: 0.5099\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 54\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4700 - mse: 0.4700 - mae: 0.5297\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 55\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4490 - mse: 0.4490 - mae: 0.5165\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 56\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4745 - mse: 0.4745 - mae: 0.5399\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 57\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4262 - mse: 0.4262 - mae: 0.4984\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 58\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4481 - mse: 0.4481 - mae: 0.5121\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 59\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4367 - mse: 0.4367 - mae: 0.5036\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4326 - mse: 0.4326 - mae: 0.5101\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 61\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4454 - mse: 0.4454 - mae: 0.5145\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 62\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4620 - mse: 0.4620 - mae: 0.5260\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 63\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4693 - mse: 0.4693 - mae: 0.5313\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 64\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4476 - mse: 0.4476 - mae: 0.5127\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 65\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4538 - mse: 0.4538 - mae: 0.5132\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 66\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4322 - mse: 0.4322 - mae: 0.4980\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 67\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4614 - mse: 0.4614 - mae: 0.5256\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 68\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4432 - mse: 0.4432 - mae: 0.5141\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 69\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4414 - mse: 0.4414 - mae: 0.5068\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 70\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4264 - mse: 0.4264 - mae: 0.4920\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 71\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4440 - mse: 0.4440 - mae: 0.5065\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 72\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4280 - mse: 0.4280 - mae: 0.4972\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 73\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4476 - mse: 0.4476 - mae: 0.5118\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 74\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4464 - mse: 0.4464 - mae: 0.5182\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4290 - mse: 0.4290 - mae: 0.5036\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 76\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4337 - mse: 0.4337 - mae: 0.5001\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 77\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4247 - mse: 0.4247 - mae: 0.5023\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 78\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4513 - mse: 0.4513 - mae: 0.5193\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "RUN: 79\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4244 - mse: 0.4244 - mae: 0.4973\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 80\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4230 - mse: 0.4230 - mae: 0.4969\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 81\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4275 - mse: 0.4275 - mae: 0.5054\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4279 - mse: 0.4279 - mae: 0.4975\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 83\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4319 - mse: 0.4319 - mae: 0.5043\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "RUN: 84\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4708 - mse: 0.4708 - mae: 0.5332\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 85\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4273 - mse: 0.4273 - mae: 0.5030\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 86\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4465 - mse: 0.4465 - mae: 0.5140\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "RUN: 87\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4383 - mse: 0.4383 - mae: 0.5151\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "RUN: 88\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4517 - mse: 0.4517 - mae: 0.5280\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "RUN: 89\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4607 - mse: 0.4607 - mae: 0.5206\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "RUN: 90\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4489 - mse: 0.4489 - mae: 0.5074\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "RUN: 91\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4657 - mse: 0.4657 - mae: 0.5306\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 92\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4400 - mse: 0.4400 - mae: 0.5073\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 93\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4195 - mse: 0.4195 - mae: 0.4930\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 94\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4143 - mse: 0.4143 - mae: 0.4854\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 95\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4322 - mse: 0.4322 - mae: 0.5068\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 96\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4396 - mse: 0.4396 - mae: 0.5116\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 97\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4506 - mse: 0.4506 - mae: 0.5132\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 98\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4210 - mse: 0.4210 - mae: 0.4888\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 99\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4370 - mse: 0.4370 - mae: 0.5043\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b24l3:        mse     mae      r2\n",
      "0   0.4867  0.5515  0.3026\n",
      "1   0.4571  0.5195  0.3451\n",
      "2   0.4444  0.5152  0.3633\n",
      "3   0.4552  0.5209  0.3478\n",
      "4   0.4297  0.5058  0.3843\n",
      "..     ...     ...     ...\n",
      "95  0.4322  0.5068  0.3808\n",
      "96  0.4396  0.5116  0.3700\n",
      "97  0.4506  0.5132  0.3544\n",
      "98  0.4210  0.4888  0.3967\n",
      "99  0.4370  0.5043  0.3739\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "Saved CNN evaluation results for b24l3 to: ../../data/evaluation_results/vae_el_b24l3.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6534 - mse: 0.6534 - mae: 0.7229\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6531 - mse: 0.6531 - mae: 0.7179\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6546 - mse: 0.6546 - mae: 0.7247\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6595 - mse: 0.6595 - mae: 0.7316\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6455 - mse: 0.6455 - mae: 0.7067\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6568 - mse: 0.6568 - mae: 0.7293\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6538 - mse: 0.6538 - mae: 0.7274\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6531 - mse: 0.6531 - mae: 0.7311\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6547 - mse: 0.6547 - mae: 0.7207\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6531 - mse: 0.6531 - mae: 0.7276\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6540 - mse: 0.6540 - mae: 0.7226\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 11\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6608 - mse: 0.6608 - mae: 0.7362\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 12\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6505 - mse: 0.6505 - mae: 0.7136\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 13\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6464 - mse: 0.6464 - mae: 0.7115\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 14\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6520 - mse: 0.6520 - mae: 0.7273\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 15\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6604 - mse: 0.6604 - mae: 0.7394\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 16\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6449 - mse: 0.6449 - mae: 0.7131\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 17\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6488 - mse: 0.6488 - mae: 0.7055\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 18\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6477 - mse: 0.6477 - mae: 0.7092\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 19\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6499 - mse: 0.6499 - mae: 0.7151\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6531 - mse: 0.6531 - mae: 0.7204\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 21\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6505 - mse: 0.6505 - mae: 0.7046\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 22\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6434 - mse: 0.6434 - mae: 0.7073\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 23\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6593 - mse: 0.6593 - mae: 0.7385\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 24\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6488 - mse: 0.6488 - mae: 0.7166\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 25\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6541 - mse: 0.6541 - mae: 0.7191\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 26\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6555 - mse: 0.6555 - mae: 0.7299\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 27\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6514 - mse: 0.6514 - mae: 0.7267\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6454 - mse: 0.6454 - mae: 0.7102\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 29\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6502 - mse: 0.6502 - mae: 0.7092\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6607 - mse: 0.6607 - mae: 0.7423\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 31\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6596 - mse: 0.6596 - mae: 0.7398\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 32\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6506 - mse: 0.6506 - mae: 0.7178\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 33\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6705 - mse: 0.6705 - mae: 0.7489\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 34\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6503 - mse: 0.6503 - mae: 0.7152\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 35\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6680 - mse: 0.6680 - mae: 0.7514\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 36\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6508 - mse: 0.6508 - mae: 0.7156\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "RUN: 37\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6708 - mse: 0.6708 - mae: 0.7545\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 38\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6572 - mse: 0.6572 - mae: 0.7371\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "RUN: 39\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6449 - mse: 0.6449 - mae: 0.7049\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "RUN: 40\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 1s 61ms/step - loss: 0.6458 - mse: 0.6458 - mae: 0.6971\n",
      "4/4 [==============================] - 1s 4ms/step\n",
      "RUN: 41\n"
     ]
    }
   ],
   "source": [
    "#evaluate_and_save_cnn(th_vae_data, 'vae', 0)\n",
    "#evaluate_and_save_cnn(th_gan_data, 'gan', 0)\n",
    "\n",
    "evaluate_and_save_cnn_blended(th_vae_data, 'vae', 0)\n",
    "evaluate_and_save_cnn_blended(th_gan_data, 'gan', 0)\n",
    "\n",
    "evaluate_and_save_cnn(el_vae_data, 'vae', 1)\n",
    "evaluate_and_save_cnn(el_gan_data, 'gan', 1)\n",
    "\n",
    "evaluate_and_save_cnn_blended(el_vae_data, 'vae', 1)\n",
    "evaluate_and_save_cnn_blended(el_gan_data, 'gan', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52621053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a919799d-e034-4e82-8459-28975d0b2fba",
   "metadata": {},
   "source": [
    "<h2> Select and compare data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30a3d709-1516-4d53-970b-5048df5adff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def find_best_model(prefix):\n",
    "    folder_path = '../../data/evaluation_results/cnn/'\n",
    "\n",
    "    file_paths = glob.glob(f'{folder_path}{prefix}*.csv')\n",
    "    \n",
    "    mse_vals = {}\n",
    "    best_val, best_df, best_name = float('inf'), None, ''\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        mse_val = df['mse'].iloc[0]\n",
    "        mse_vals[file_path] = mse_val\n",
    "        \n",
    "        if mse_val < best_val:\n",
    "            best_val, best_df = mse_val, df\n",
    "            best_name = file_path.split('/')[-1]\n",
    "\n",
    "    sorted_mse_vals = sorted(mse_vals.items(), key=lambda item: item[1])\n",
    "    \n",
    "    for name, value in sorted_mse_vals:\n",
    "        print(name.split('/')[-1], value)\n",
    "        \n",
    "    print(f'\\nDataFrame with lowest MSE ({best_name}):\\n{best_df}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c952fd1-f985-4683-b84c-f1b3cda8b909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Thermal\n",
      "cnn\\vae_th_b20l3.csv 0.1190055929124355\n",
      "cnn\\vae_th_b8l15.csv 0.1265775240957737\n",
      "cnn\\vae_th_b16l5.csv 0.1314404964447021\n",
      "cnn\\vae_th_b4l5.csv 0.1364974901080131\n",
      "cnn\\vae_th_b20l5.csv 0.1520956456661224\n",
      "cnn\\vae_th_b24l15.csv 0.1523252636194229\n",
      "cnn\\vae_th_b4l10.csv 0.1532680049538612\n",
      "cnn\\vae_th_b24l50.csv 0.1778552532196045\n",
      "cnn\\vae_th_b16l10.csv 0.1802604213356971\n",
      "cnn\\vae_th_b8l20.csv 0.5562011629343033\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\vae_th_b20l3.csv):\n",
      "   Unnamed: 0    mse     mae      r2\n",
      "0           0  0.119  0.2626  0.3321\n",
      "\n",
      "cnn\\gan_th_b8e1000.csv 0.2068981036543846\n",
      "cnn\\gan_th_b32e100.csv 0.2844437450170517\n",
      "cnn\\gan_th_b8e500.csv 0.2867301911115646\n",
      "cnn\\gan_th_b20e100.csv 0.3444884002208709\n",
      "cnn\\gan_th_b6e100.csv 0.4662655055522918\n",
      "cnn\\gan_th_b32e500.csv 0.5470245212316514\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\gan_th_b8e1000.csv):\n",
      "   Unnamed: 0     mse     mae      r2\n",
      "0           0  0.2069  0.3807 -0.1612\n",
      "\n",
      "\n",
      "Context: Electrical\n",
      "cnn\\vae_el_b8l10.csv 0.4488880276679993\n",
      "cnn\\vae_el_b24l3.csv 0.460650372505188\n",
      "cnn\\vae_el_b32l3.csv 0.4674365490674972\n",
      "cnn\\vae_el_b20l3.csv 0.4794443905353546\n",
      "cnn\\vae_el_b32l5.csv 0.4821873813867569\n",
      "cnn\\vae_el_b4l3.csv 0.5005753338336945\n",
      "cnn\\vae_el_b20l20.csv 0.535299152135849\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\vae_el_b8l10.csv):\n",
      "   Unnamed: 0     mse     mae      r2\n",
      "0           0  0.4489  0.5438  0.3568\n",
      "\n",
      "cnn\\gan_el_b20e500.csv 0.6525217473506928\n",
      "cnn\\gan_el_b24e1000.csv 0.6589860200881958\n",
      "cnn\\gan_el_b4e1000.csv 0.6608556270599365\n",
      "cnn\\gan_el_b10e100.csv 0.6903378903865814\n",
      "cnn\\gan_el_b32e1000.csv 0.7058127760887146\n",
      "cnn\\gan_el_b16e500.csv 0.7213095486164093\n",
      "cnn\\gan_el_b8e1000.csv 0.7526354789733887\n",
      "cnn\\gan_el_b12e100.csv 0.7568051278591156\n",
      "cnn\\gan_el_b8e500.csv 0.7750153601169586\n",
      "cnn\\gan_el_b6e100.csv 0.7756770730018616\n",
      "cnn\\gan_el_b12e500.csv 1.2655772984027862\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\gan_el_b20e500.csv):\n",
      "   Unnamed: 0     mse     mae     r2\n",
      "0           0  0.6525  0.7187  0.065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Context: Thermal')\n",
    "find_best_model('vae_th')\n",
    "find_best_model('gan_th')\n",
    "\n",
    "print('\\nContext: Electrical')\n",
    "find_best_model('vae_el')\n",
    "find_best_model('gan_el')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88edc2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Thermal\n",
      "cnn\\vae_blended_th_b20l3.csv 0.0781151488423347\n",
      "cnn\\vae_blended_th_b4l10.csv 0.0924433469772338\n",
      "cnn\\vae_blended_th_b8l15.csv 0.0932417020201683\n",
      "cnn\\vae_blended_th_b4l5.csv 0.0968162976205349\n",
      "cnn\\vae_blended_th_b24l15.csv 0.09766411408782\n",
      "cnn\\vae_blended_th_b16l5.csv 0.1016411677002906\n",
      "cnn\\vae_blended_th_b20l5.csv 0.1065429620444774\n",
      "cnn\\vae_blended_th_b24l50.csv 0.1090219363570213\n",
      "cnn\\vae_blended_th_b16l10.csv 0.120886443555355\n",
      "cnn\\vae_blended_th_b8l20.csv 0.1320243626832962\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\vae_blended_th_b20l3.csv):\n",
      "   Unnamed: 0     mse     mae      r2\n",
      "0           0  0.0781  0.2037  0.5616\n",
      "\n",
      "cnn\\gan_blended_th_b20e100.csv 0.0895717576146125\n",
      "cnn\\gan_blended_th_b32e500.csv 0.1010843776166439\n",
      "cnn\\gan_blended_th_b8e1000.csv 0.1029256179928779\n",
      "cnn\\gan_blended_th_b32e100.csv 0.1281974203884601\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\gan_blended_th_b20e100.csv):\n",
      "   Unnamed: 0     mse     mae      r2\n",
      "0           0  0.0896  0.2154  0.4973\n",
      "\n",
      "\n",
      "Context: Electrical\n",
      "cnn\\vae_blended_el_b20l3.csv 0.2535918995738029\n",
      "cnn\\vae_blended_el_b24l3.csv 0.2749372079968452\n",
      "cnn\\vae_blended_el_b32l3.csv 0.2798540830612183\n",
      "cnn\\vae_blended_el_b32l5.csv 0.2960797667503357\n",
      "cnn\\vae_blended_el_b8l10.csv 0.2969275802373886\n",
      "cnn\\vae_blended_el_b4l3.csv 0.301945886015892\n",
      "cnn\\vae_blended_el_b20l20.csv 0.3226022779941558\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\vae_blended_el_b20l3.csv):\n",
      "   Unnamed: 0     mse     mae      r2\n",
      "0           0  0.2536  0.3789  0.6366\n",
      "\n",
      "cnn\\gan_blended_el_b12e100.csv 0.2843874543905258\n",
      "cnn\\gan_blended_el_b12e500.csv 0.3095213562250137\n",
      "cnn\\gan_blended_el_b20e500.csv 0.329680386185646\n",
      "cnn\\gan_blended_el_b10e100.csv 0.333711576461792\n",
      "cnn\\gan_blended_el_b6e100.csv 0.3351649463176727\n",
      "cnn\\gan_blended_el_b4e1000.csv 0.3837144494056702\n",
      "cnn\\gan_blended_el_b24e1000.csv 0.3885896325111389\n",
      "cnn\\gan_blended_el_b16e500.csv 0.4024775505065918\n",
      "cnn\\gan_blended_el_b32e1000.csv 0.4125942677259445\n",
      "cnn\\gan_blended_el_b8e1000.csv 0.4157545506954193\n",
      "cnn\\gan_blended_el_b8e500.csv 0.4408891141414642\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\gan_blended_el_b12e100.csv):\n",
      "   Unnamed: 0     mse     mae      r2\n",
      "0           0  0.2844  0.4065  0.5925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Context: Thermal')\n",
    "find_best_model('vae_blended_th')\n",
    "find_best_model('gan_blended_th')\n",
    "\n",
    "print('\\nContext: Electrical')\n",
    "find_best_model('vae_blended_el')\n",
    "find_best_model('gan_blended_el')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce785e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
