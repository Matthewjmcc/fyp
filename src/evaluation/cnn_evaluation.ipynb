{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5604aa68-cdae-4f79-97d3-34e182a0ca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 15:40:56.681061: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-09 15:40:56.681205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-09 15:40:56.840447: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-09 15:40:57.272159: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-09 15:41:02.695495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, tensorflow as tf\n",
    "import sys, time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dropout, MaxPooling1D, GlobalAveragePooling1D, Conv1DTranspose, LSTM, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.precision', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137720cc-886d-4641-9490-0bf697082df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - ss_res/(ss_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414b045b-f57d-495c-beb8-b710c55370dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_train, base_data_test = np.load('../../data/training_data/training_data_1month.npy', allow_pickle=True)\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e3ed8d-a134-4ffb-94de-6e79786ca695",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2> Scale Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90635f26-def5-40d8-a820-3150b41f9a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 730, 4) (108, 730, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "base_data_train, base_data_test = np.load('../../data/training_data/training_data_1month.npy', allow_pickle=True)\n",
    "scalers = {var_name: MinMaxScaler(feature_range=(-1,1)) for var_name in ['G.air.T', 'G.E_th_I', 'G.sky.T', 'G.E_el_I']}\n",
    "\n",
    "air_var, sky_var, el_var, th_var = base_data_train[:,:,0], base_data_train[:,:,1], base_data_train[:,:,2], base_data_train[:,:,3]\n",
    "air_var_test, sky_var_test, el_var_test, th_var_test = base_data_test[:,:,0], base_data_test[:,:,1], base_data_test[:,:,2], base_data_test[:,:,3]\n",
    "\n",
    "scaled_data_train = np.stack((scalers['G.air.T'].fit_transform(air_var),\n",
    "                             scalers['G.sky.T'].fit_transform(sky_var),\n",
    "                             scalers['G.E_el_I'].fit_transform(el_var),\n",
    "                             scalers['G.E_th_I'].fit_transform(th_var)), axis=-1)\n",
    "scaled_data_test = np.stack((scalers['G.air.T'].fit_transform(air_var),\n",
    "                             scalers['G.sky.T'].fit_transform(sky_var),\n",
    "                             scalers['G.E_el_I'].fit_transform(el_var),\n",
    "                             scalers['G.E_th_I'].fit_transform(th_var)), axis=-1)\n",
    "print(scaled_data_train.shape, scaled_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be189d7-6067-4652-8dc0-f688acece12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 730, 2) (12, 730, 2) (108, 730, 2) (12, 730, 2)\n"
     ]
    }
   ],
   "source": [
    "def split_base_data(base_data_train, base_data_test, th_indices=[0, 3], el_indices=[1, 2]):\n",
    "    th_base_data_train, th_base_data_test = base_data_train[:, :, th_indices], base_data_test[:, :, th_indices]\n",
    "    el_base_data_train, el_base_data_test = base_data_train[:, :, el_indices], base_data_test[:, :, el_indices]\n",
    "    return th_base_data_train, th_base_data_test, el_base_data_train, el_base_data_test\n",
    "\n",
    "th_base_data_train, th_base_data_test, el_base_data_train, el_base_data_test = split_base_data(base_data_train, base_data_test)\n",
    "print(th_base_data_train.shape, th_base_data_test.shape, el_base_data_train.shape, el_base_data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff891f3-88f4-4fec-95fb-c99b90a73ace",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2> CNN Models</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a190fe07-f580-4d55-9daf-dbcbe79b8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=24, activation='relu', input_shape=(input_shape)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Conv1D(filters=64, kernel_size=24, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(730, activation='linear')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a72256e-8e9d-4013-90ce-1b4cae833dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn(training_data, th_or_el):\n",
    "    X_train = training_data[:,:,0].reshape(-1,730,1)\n",
    "    y_train = training_data[:,:,1]\n",
    "\n",
    "    if th_or_el == 0:\n",
    "        X_test = scaled_data_test[:,:,0].reshape(-1, 730, 1)  \n",
    "        y_test = scaled_data_test[:,:,3]\n",
    "    else:\n",
    "        X_test = scaled_data_test[:,:,1].reshape(-1, 730, 1)  \n",
    "        y_test = scaled_data_test[:,:,2]\n",
    "\n",
    "    X_train, X_train_val, y_train, y_train_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)\n",
    "                                                                  \n",
    "    model = create_cnn((X_train.shape[1], X_train.shape[2]))\n",
    "    model.compile(optimizer=Adam(), loss='mse', metrics=['mse', 'mae'])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='mse', patience=10, verbose=1, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='mse', factor=0.5, patience=5, verbose=1)\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=16, callbacks=[early_stopping, reduce_lr], verbose=0, validation_data=(X_train_val, y_train_val))\n",
    "\n",
    "    loss, mse, mae = model.evaluate(X_test, y_test)\n",
    "    r2 = r_squared(tf.convert_to_tensor(y_test, dtype=tf.float32), tf.convert_to_tensor(model.predict(X_test), dtype=tf.float32))\n",
    "    \n",
    "    return {'mse':mse, 'mae':mae, 'r2':r2.numpy()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc6be8c1-0a57-414d-8461-866b41a76655",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reps = 100\n",
    "\n",
    "def test_cnn_wrapper(data, th_or_el=0):\n",
    "    mse, mae, r2 = [], [], []\n",
    "    \n",
    "    # Run each CNN training 10 times to ensure results are significant and not outliers\n",
    "    for i in range(num_reps):\n",
    "        print(f'RUN: {i}')\n",
    "        results = test_cnn(np.random.permutation(data), th_or_el) # permuting the data for each run just to ensure full shuffling\n",
    "        mse.append(results['mse'])\n",
    "        mae.append(results['mae'])\n",
    "        r2.append(results['r2'])\n",
    "\n",
    "    return {'mse':mse, 'mae':mae, 'r2':r2}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa06e5-c9b5-461f-bc7a-98375e2994e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a02e7804-5dee-469e-881c-6d0f2648e6d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2> Load data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "763f646c-f6c2-45e3-bb6c-f2ce3b45bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_path, context, dataset_names):\n",
    "    datasets = {}\n",
    "    for name in dataset_names:\n",
    "        file_path = f'{base_path}/{context}_{name}_generated_samples.npy'\n",
    "        datasets[name] = np.load(file_path, allow_pickle=True)\n",
    "    return datasets\n",
    "\n",
    "base_path_vae = '../../data/vae_synthetic_data/'\n",
    "base_path_gan = '../../data/gan_synthetic_data/'\n",
    "th_context = 'th_v_air'\n",
    "el_context = 'el_v_sky'\n",
    "\n",
    "th_vae_datasets = ['b20l5', 'b4l10', 'b16l10', 'b8l20', 'b4l5', 'b16l5', 'b20l3', 'b24l15', 'b8l15', 'b24l50']\n",
    "th_gan_datasets = ['b32e500', 'b8e1000', 'b20e100', 'b32e100', 'b6e100', 'b8e500']\n",
    "\n",
    "th_vae_data = load_data(base_path_vae, th_context, th_vae_datasets)\n",
    "th_gan_data = load_data(base_path_gan, th_context, th_gan_datasets)\n",
    "\n",
    "el_vae_datasets = ['b4l3', 'b8l10', 'b20l3', 'b20l20', 'b24l3', 'b32l3', 'b32l5']\n",
    "el_gan_datasets = ['b4e1000','b6e100','b8e500','b8e1000', 'b10e100', 'b12e100', 'b12e500', 'b16e500', 'b20e500', 'b24e1000', 'b32e1000']\n",
    "\n",
    "el_vae_data = load_data(base_path_vae, el_context, el_vae_datasets)\n",
    "el_gan_data = load_data(base_path_gan, el_context, el_gan_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a44b057e-c56d-426e-a61a-0fc5c5d6706a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [(1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2)]\n",
      "6 [(1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2)]\n",
      "7 [(1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2)]\n",
      "11 [(1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2), (1000, 730, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(len(th_vae_data), [th_vae_data[th_vae_datasets[i]].shape for i in range(len(th_vae_data))])\n",
    "print(len(th_gan_data), [th_gan_data[th_gan_datasets[i]].shape for i in range(len(th_gan_data))])\n",
    "\n",
    "print(len(el_vae_data), [el_vae_data[el_vae_datasets[i]].shape for i in range(len(el_vae_data))])\n",
    "print(len(el_gan_data), [el_gan_data[el_gan_datasets[i]].shape for i in range(len(el_gan_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f6341-ad77-404e-a731-5d672b788255",
   "metadata": {},
   "source": [
    "<h2> Train CNNs </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e32ba9-d65f-4a89-ab8a-d895cfc9a5cd",
   "metadata": {},
   "source": [
    "<h3> Ground Truth Datasets </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3414deb-dd19-47d4-82b9-c03f4137584a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0983 - mse: 0.0983 - mae: 0.2335\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0973 - mse: 0.0973 - mae: 0.2308\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1053 - mse: 0.1053 - mae: 0.2429\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1008 - mse: 0.1008 - mae: 0.2336\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1032 - mse: 0.1032 - mae: 0.2356\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1033 - mse: 0.1033 - mae: 0.2437\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0956 - mse: 0.0956 - mae: 0.2261\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0953 - mse: 0.0953 - mae: 0.2245\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0972 - mse: 0.0972 - mae: 0.2371\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0967 - mse: 0.0967 - mae: 0.2362\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 10\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0949 - mse: 0.0949 - mae: 0.2399\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 11\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0963 - mse: 0.0963 - mae: 0.2261\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 12\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1009 - mse: 0.1009 - mae: 0.2330\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 13\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1015 - mse: 0.1015 - mae: 0.2455\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 14\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0947 - mse: 0.0947 - mae: 0.2243\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 15\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1064 - mse: 0.1064 - mae: 0.2458\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 16\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0954 - mse: 0.0954 - mae: 0.2337\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 17\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0944 - mse: 0.0944 - mae: 0.2308\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 18\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0965 - mse: 0.0965 - mae: 0.2334\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 19\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0937 - mse: 0.0937 - mae: 0.2308\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 20\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1045 - mse: 0.1045 - mae: 0.2425\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 21\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0912 - mse: 0.0912 - mae: 0.2226\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 22\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0969 - mse: 0.0969 - mae: 0.2268\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 23\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1024 - mse: 0.1024 - mae: 0.2383\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 24\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1093 - mse: 0.1093 - mae: 0.2518\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 25\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2164\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 26\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1102 - mse: 0.1102 - mae: 0.2538\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 27\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1090 - mse: 0.1090 - mae: 0.2453\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 28\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1055 - mse: 0.1055 - mae: 0.2425\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 29\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1021 - mse: 0.1021 - mae: 0.2390\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 30\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1015 - mse: 0.1015 - mae: 0.2331\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 31\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0945 - mse: 0.0945 - mae: 0.2327\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 32\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1038 - mse: 0.1038 - mae: 0.2489\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 33\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1016 - mse: 0.1016 - mae: 0.2355\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 34\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0966 - mse: 0.0966 - mae: 0.2245\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 35\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0961 - mse: 0.0961 - mae: 0.2300\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 36\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0925 - mse: 0.0925 - mae: 0.2161\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 37\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1036 - mse: 0.1036 - mae: 0.2412\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 38\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0993 - mse: 0.0993 - mae: 0.2363\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 39\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0993 - mse: 0.0993 - mae: 0.2289\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0950 - mse: 0.0950 - mae: 0.2325\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 41\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0981 - mse: 0.0981 - mae: 0.2319\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 42\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0922 - mse: 0.0922 - mae: 0.2174\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 43\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0903 - mse: 0.0903 - mae: 0.2147\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 44\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1002 - mse: 0.1002 - mae: 0.2364\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 45\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0953 - mse: 0.0953 - mae: 0.2246\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 46\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0984 - mse: 0.0984 - mae: 0.2275\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 47\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1062 - mse: 0.1062 - mae: 0.2517\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 48\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0971 - mse: 0.0971 - mae: 0.2369\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 49\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0992 - mse: 0.0992 - mae: 0.2262\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1055 - mse: 0.1055 - mae: 0.2499\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 51\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0971 - mse: 0.0971 - mae: 0.2255\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 52\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1006 - mse: 0.1006 - mae: 0.2465\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 53\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0963 - mse: 0.0963 - mae: 0.2271\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 54\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0911 - mse: 0.0911 - mae: 0.2226\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 55\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0958 - mse: 0.0958 - mae: 0.2314\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 56\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0968 - mse: 0.0968 - mae: 0.2265\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 57\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1057 - mse: 0.1057 - mae: 0.2513\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 58\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0929 - mse: 0.0929 - mae: 0.2258\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 59\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0973 - mse: 0.0973 - mae: 0.2252\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0992 - mse: 0.0992 - mae: 0.2383\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 61\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1059 - mse: 0.1059 - mae: 0.2463\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 62\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1037 - mse: 0.1037 - mae: 0.2362\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 63\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0979 - mse: 0.0979 - mae: 0.2353\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 64\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1066 - mse: 0.1066 - mae: 0.2403\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 65\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1034 - mse: 0.1034 - mae: 0.2427\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 66\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0995 - mse: 0.0995 - mae: 0.2394\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 67\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0964 - mse: 0.0964 - mae: 0.2331\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 68\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0992 - mse: 0.0992 - mae: 0.2373\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 69\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1015 - mse: 0.1015 - mae: 0.2355\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 70\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0959 - mse: 0.0959 - mae: 0.2323\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 71\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1076 - mse: 0.1076 - mae: 0.2550\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 72\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0959 - mse: 0.0959 - mae: 0.2247\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 73\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0925 - mse: 0.0925 - mae: 0.2298\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 74\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1033 - mse: 0.1033 - mae: 0.2481\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 75\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1017 - mse: 0.1017 - mae: 0.2330\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 76\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1002 - mse: 0.1002 - mae: 0.2326\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 77\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0981 - mse: 0.0981 - mae: 0.2309\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 78\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1045 - mse: 0.1045 - mae: 0.2398\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 79\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0927 - mse: 0.0927 - mae: 0.2173\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 80\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1036 - mse: 0.1036 - mae: 0.2396\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 81\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1066 - mse: 0.1066 - mae: 0.2551\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 82\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1035 - mse: 0.1035 - mae: 0.2383\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 83\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0978 - mse: 0.0978 - mae: 0.2330\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 84\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0992 - mse: 0.0992 - mae: 0.2322\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 85\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0971 - mse: 0.0971 - mae: 0.2293\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 86\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0883 - mse: 0.0883 - mae: 0.2160\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 87\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1052 - mse: 0.1052 - mae: 0.2469\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 88\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0968 - mse: 0.0968 - mae: 0.2296\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 89\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0976 - mse: 0.0976 - mae: 0.2322\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 90\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0908 - mse: 0.0908 - mae: 0.2207\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 91\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0908 - mse: 0.0908 - mae: 0.2134\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 92\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1019 - mse: 0.1019 - mae: 0.2461\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 93\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0947 - mse: 0.0947 - mae: 0.2264\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 94\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0957 - mse: 0.0957 - mae: 0.2246\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 95\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1043 - mse: 0.1043 - mae: 0.2450\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 96\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1026 - mse: 0.1026 - mae: 0.2363\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 97\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1057 - mse: 0.1057 - mae: 0.2439\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 98\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0954 - mse: 0.0954 - mae: 0.2218\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 99\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1051 - mse: 0.1051 - mae: 0.2456\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2621 - mse: 0.2621 - mae: 0.3787\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2640 - mse: 0.2640 - mae: 0.3944\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3511 - mse: 0.3511 - mae: 0.4611\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2770 - mse: 0.2770 - mae: 0.3941\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3242 - mse: 0.3242 - mae: 0.4398\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2810 - mse: 0.2810 - mae: 0.4070\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2831 - mse: 0.2831 - mae: 0.4020\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2744 - mse: 0.2744 - mae: 0.3960\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2783 - mse: 0.2783 - mae: 0.3973\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2692 - mse: 0.2692 - mae: 0.3943\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 10\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2864 - mse: 0.2864 - mae: 0.4037\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 11\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2860 - mse: 0.2860 - mae: 0.4045\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 12\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2694 - mse: 0.2694 - mae: 0.3912\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 13\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3038 - mse: 0.3038 - mae: 0.4258\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 14\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2859 - mse: 0.2859 - mae: 0.4073\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 15\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2891 - mse: 0.2891 - mae: 0.4122\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 16\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2890 - mse: 0.2890 - mae: 0.4090\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 17\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2994 - mse: 0.2994 - mae: 0.4218\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 18\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2744 - mse: 0.2744 - mae: 0.4063\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 19\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3061 - mse: 0.3061 - mae: 0.4279\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 20\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2774 - mse: 0.2774 - mae: 0.3986\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 21\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2962 - mse: 0.2962 - mae: 0.4230\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 22\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2907 - mse: 0.2907 - mae: 0.4111\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 23\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2778 - mse: 0.2778 - mae: 0.4049\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 24\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2753 - mse: 0.2753 - mae: 0.4017\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 25\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2843 - mse: 0.2843 - mae: 0.4074\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 26\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2872 - mse: 0.2872 - mae: 0.4114\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 27\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2642 - mse: 0.2642 - mae: 0.3795\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 28\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2985 - mse: 0.2985 - mae: 0.4178\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 29\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2996 - mse: 0.2996 - mae: 0.4239\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 30\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2839 - mse: 0.2839 - mae: 0.4052\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 31\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2955 - mse: 0.2955 - mae: 0.4204\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 32\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2767 - mse: 0.2767 - mae: 0.3985\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 33\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2526 - mse: 0.2526 - mae: 0.3757\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 34\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2862 - mse: 0.2862 - mae: 0.4097\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 35\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2819 - mse: 0.2819 - mae: 0.4084\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 36\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2848 - mse: 0.2848 - mae: 0.4077\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 37\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2779 - mse: 0.2779 - mae: 0.4006\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 38\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2830 - mse: 0.2830 - mae: 0.4108\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 39\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2943 - mse: 0.2943 - mae: 0.4101\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 40\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3266 - mse: 0.3266 - mae: 0.4495\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 41\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2709 - mse: 0.2709 - mae: 0.3966\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 42\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2720 - mse: 0.2720 - mae: 0.3964\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 43\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2455 - mse: 0.2455 - mae: 0.3716\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 44\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2847 - mse: 0.2847 - mae: 0.4050\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 45\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2828 - mse: 0.2828 - mae: 0.4009\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 46\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2714 - mse: 0.2714 - mae: 0.3930\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 47\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2798 - mse: 0.2798 - mae: 0.3984\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 48\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3557 - mse: 0.3557 - mae: 0.4601\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 49\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3391 - mse: 0.3391 - mae: 0.4567\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 50\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2918 - mse: 0.2918 - mae: 0.4115\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 51\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2663 - mse: 0.2663 - mae: 0.3951\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 52\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2648 - mse: 0.2648 - mae: 0.3910\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 53\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3005 - mse: 0.3005 - mae: 0.4197\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 54\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2841 - mse: 0.2841 - mae: 0.4040\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 55\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2907 - mse: 0.2907 - mae: 0.4126\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 56\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2641 - mse: 0.2641 - mae: 0.3832\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 57\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2977 - mse: 0.2977 - mae: 0.4202\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 58\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2698 - mse: 0.2698 - mae: 0.3969\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 59\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2914 - mse: 0.2914 - mae: 0.4151\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 60\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2675 - mse: 0.2675 - mae: 0.3905\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 61\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2761 - mse: 0.2761 - mae: 0.3994\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 62\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3079 - mse: 0.3079 - mae: 0.4294\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 63\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3181 - mse: 0.3181 - mae: 0.4344\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 64\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3000 - mse: 0.3000 - mae: 0.4192\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 65\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2659 - mse: 0.2659 - mae: 0.3923\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 66\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2735 - mse: 0.2735 - mae: 0.3938\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 67\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3145 - mse: 0.3145 - mae: 0.4362\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 68\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3180 - mse: 0.3180 - mae: 0.4342\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 69\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2858 - mse: 0.2858 - mae: 0.4097\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 70\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2789 - mse: 0.2789 - mae: 0.4035\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 71\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3050 - mse: 0.3050 - mae: 0.4276\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 72\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3041 - mse: 0.3041 - mae: 0.4236\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 73\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3077 - mse: 0.3077 - mae: 0.4214\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 74\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2915 - mse: 0.2915 - mae: 0.4153\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 75\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2805 - mse: 0.2805 - mae: 0.4014\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 76\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3054 - mse: 0.3054 - mae: 0.4194\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 77\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2760 - mse: 0.2760 - mae: 0.3961\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 78\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2803 - mse: 0.2803 - mae: 0.4020\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 79\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3030 - mse: 0.3030 - mae: 0.4203\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 80\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3056 - mse: 0.3056 - mae: 0.4293\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 81\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2926 - mse: 0.2926 - mae: 0.4099\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 82\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2634 - mse: 0.2634 - mae: 0.3854\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 83\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2930 - mse: 0.2930 - mae: 0.4202\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 84\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3065 - mse: 0.3065 - mae: 0.4215\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 85\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3261 - mse: 0.3261 - mae: 0.4437\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 86\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2887 - mse: 0.2887 - mae: 0.4097\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 87\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2617 - mse: 0.2617 - mae: 0.3936\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 88\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2786 - mse: 0.2786 - mae: 0.3949\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 89\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2937 - mse: 0.2937 - mae: 0.4102\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 90\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2670 - mse: 0.2670 - mae: 0.3915\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 91\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2749 - mse: 0.2749 - mae: 0.3955\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 92\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3055 - mse: 0.3055 - mae: 0.4236\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 93\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3091 - mse: 0.3091 - mae: 0.4357\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 94\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2956 - mse: 0.2956 - mae: 0.4177\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2727 - mse: 0.2727 - mae: 0.3990\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 96\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2991 - mse: 0.2991 - mae: 0.4211\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 97\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2856 - mse: 0.2856 - mae: 0.4051\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 98\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2837 - mse: 0.2837 - mae: 0.4076\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 99\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2696 - mse: 0.2696 - mae: 0.3918\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(test_cnn_wrapper(scaled_data_train[:,:,[0,3]], 0)).to_csv('../../data/evaluation_results/th_gt.csv', index=False)\n",
    "pd.DataFrame(test_cnn_wrapper(scaled_data_train[:,:,[1,2]], 1)).to_csv('../../data/evaluation_results/el_gt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a587c960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09846784219145771 0.286872461438179\n"
     ]
    }
   ],
   "source": [
    "th_gt, el_gt = pd.read_csv('../../data/evaluation_results/th_gt.csv'), pd.read_csv('../../data/evaluation_results/el_gt.csv')\n",
    "\n",
    "print(np.mean(th_gt['mse']), np.mean(el_gt['mse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c34e06-8cec-455c-9750-c3dedae82445",
   "metadata": {},
   "source": [
    "<h3> Synthetic Datasets </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ab1da6-24d3-494d-b94b-6d5b9834e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_cnn(data_dicts, model_type, column_index, base_path='../../data/evaluation_results/'):\n",
    "    for dataset_name, dataset in data_dicts.items():\n",
    "        cnn_test_results = test_cnn_wrapper(dataset[0:216, :, :], column_index)\n",
    "\n",
    "        result_df = pd.DataFrame(cnn_test_results)\n",
    "        result_file_name = f'{base_path}{model_type}_{\"th\" if column_index==0 else \"el\"}_{dataset_name}.csv'\n",
    "        result_df.to_csv(result_file_name)\n",
    "        print(f'CNN results for {dataset_name}: {result_df}')\n",
    "        print(f'Saved CNN evaluation results for {dataset_name} to: {result_file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f7849-ccd0-4196-9af6-87c4a1edba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_save_cnn(th_vae_data, 'vae', 0)\n",
    "evaluate_and_save_cnn(th_gan_data, 'gan', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7fd40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_save_cnn(el_vae_data, 'vae', 1)\n",
    "evaluate_and_save_cnn(el_gan_data, 'gan', 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a037f92-ded3-42b4-aefc-306d635935c0",
   "metadata": {},
   "source": [
    "<h3> Blended Datasets </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f99b5a33-68f9-415e-82c3-42ff685781ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_cnn_blended(data_dicts, model_type, column_index, base_path='../../data/evaluation_results/'):\n",
    "    for dataset_name, dataset in data_dicts.items():\n",
    "        scaled_data = scaled_data_train[:,:,[0,3]] if column_index==0 else scaled_data_train[:,:,[1,2]]\n",
    "        cnn_test_results = test_cnn_wrapper(np.concatenate((scaled_data, dataset[0:216,:,:]), axis=0), column_index)\n",
    "\n",
    "        result_df = pd.DataFrame(cnn_test_results)\n",
    "        result_file_name = f'{base_path}{model_type}_blended_{\"th\" if column_index==0 else \"el\"}_{dataset_name}.csv'\n",
    "        result_df.to_csv(result_file_name)\n",
    "        print(f'CNN results for {dataset_name}: {result_df}')\n",
    "        print(f'Saved CNN evaluation results for {dataset_name} to: {result_file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b4d32-80d8-4d5f-b767-7a26ab07af24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_and_save_cnn_blended(th_vae_data, 'vae', 0)\n",
    "evaluate_and_save_cnn_blended(th_gan_data, 'gan', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e12066c1-16c7-4313-8c7e-04229b7a4910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3205 - mse: 0.3205 - mae: 0.4372\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3218 - mse: 0.3218 - mae: 0.4411\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3123 - mse: 0.3123 - mae: 0.4293\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2751 - mse: 0.2751 - mae: 0.4008\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2801 - mse: 0.2801 - mae: 0.4031\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3252 - mse: 0.3252 - mae: 0.4391\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2820 - mse: 0.2820 - mae: 0.4005\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3018 - mse: 0.3018 - mae: 0.4191\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3100 - mse: 0.3100 - mae: 0.4239\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2905 - mse: 0.2905 - mae: 0.4094\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b4l3:         mse       mae       r2\n",
      "0  0.301946  0.420358  0.56735\n",
      "Saved CNN evaluation results for b4l3 to: ../../data/evaluation_results/vae_blended_el_b4l3.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2919 - mse: 0.2919 - mae: 0.4169\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2942 - mse: 0.2942 - mae: 0.4155\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2829 - mse: 0.2829 - mae: 0.4097\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2541 - mse: 0.2541 - mae: 0.3850\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2772 - mse: 0.2772 - mae: 0.4066\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2786 - mse: 0.2786 - mae: 0.4086\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3218 - mse: 0.3218 - mae: 0.4419\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3120 - mse: 0.3120 - mae: 0.4330\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3484 - mse: 0.3484 - mae: 0.4620\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3081 - mse: 0.3081 - mae: 0.4284\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b8l10:         mse       mae       r2\n",
      "0  0.296928  0.420767  0.57454\n",
      "Saved CNN evaluation results for b8l10 to: ../../data/evaluation_results/vae_blended_el_b8l10.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2310 - mse: 0.2310 - mae: 0.3563\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2563 - mse: 0.2563 - mae: 0.3803\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2774 - mse: 0.2774 - mae: 0.3959\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2254 - mse: 0.2254 - mae: 0.3504\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2331 - mse: 0.2331 - mae: 0.3656\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2788 - mse: 0.2788 - mae: 0.4031\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2822 - mse: 0.2822 - mae: 0.4004\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2316 - mse: 0.2316 - mae: 0.3653\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2652 - mse: 0.2652 - mae: 0.3885\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2548 - mse: 0.2548 - mae: 0.3831\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b20l3:         mse       mae        r2\n",
      "0  0.253592  0.378871  0.636635\n",
      "Saved CNN evaluation results for b20l3 to: ../../data/evaluation_results/vae_blended_el_b20l3.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3507 - mse: 0.3507 - mae: 0.4612\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3315 - mse: 0.3315 - mae: 0.4481\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3312 - mse: 0.3312 - mae: 0.4562\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2836 - mse: 0.2836 - mae: 0.4058\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2704 - mse: 0.2704 - mae: 0.3993\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3650 - mse: 0.3650 - mae: 0.4648\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4002 - mse: 0.4002 - mae: 0.5016\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2902 - mse: 0.2902 - mae: 0.4158\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3227 - mse: 0.3227 - mae: 0.4394\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2807 - mse: 0.2807 - mae: 0.4077\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b20l20:         mse       mae        r2\n",
      "0  0.322602  0.439988  0.537752\n",
      "Saved CNN evaluation results for b20l20 to: ../../data/evaluation_results/vae_blended_el_b20l20.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2780 - mse: 0.2780 - mae: 0.3972\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2574 - mse: 0.2574 - mae: 0.3782\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2652 - mse: 0.2652 - mae: 0.3863\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2546 - mse: 0.2546 - mae: 0.3768\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2741 - mse: 0.2741 - mae: 0.3954\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2848 - mse: 0.2848 - mae: 0.4027\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2751 - mse: 0.2751 - mae: 0.3982\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2463 - mse: 0.2463 - mae: 0.3659\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3057 - mse: 0.3057 - mae: 0.4176\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3083 - mse: 0.3083 - mae: 0.4234\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b24l3:         mse       mae       r2\n",
      "0  0.274937  0.394183  0.60605\n",
      "Saved CNN evaluation results for b24l3 to: ../../data/evaluation_results/vae_blended_el_b24l3.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2970 - mse: 0.2970 - mae: 0.4155\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2528 - mse: 0.2528 - mae: 0.3761\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2869 - mse: 0.2869 - mae: 0.4094\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3120 - mse: 0.3120 - mae: 0.4258\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2469 - mse: 0.2469 - mae: 0.3741\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2979 - mse: 0.2979 - mae: 0.4122\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2688 - mse: 0.2688 - mae: 0.3894\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2772 - mse: 0.2772 - mae: 0.4001\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2762 - mse: 0.2762 - mae: 0.3975\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2827 - mse: 0.2827 - mae: 0.4045\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b32l3:         mse      mae        r2\n",
      "0  0.279854  0.40045  0.599004\n",
      "Saved CNN evaluation results for b32l3 to: ../../data/evaluation_results/vae_blended_el_b32l3.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3079 - mse: 0.3079 - mae: 0.4431\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2964 - mse: 0.2964 - mae: 0.4191\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2921 - mse: 0.2921 - mae: 0.4193\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3281 - mse: 0.3281 - mae: 0.4441\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3550 - mse: 0.3550 - mae: 0.4652\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2620 - mse: 0.2620 - mae: 0.3884\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2674 - mse: 0.2674 - mae: 0.3958\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2798 - mse: 0.2798 - mae: 0.4056\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3100 - mse: 0.3100 - mae: 0.4287\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2622 - mse: 0.2622 - mae: 0.3925\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b32l5:        mse       mae        r2\n",
      "0  0.29608  0.420178  0.575755\n",
      "Saved CNN evaluation results for b32l5 to: ../../data/evaluation_results/vae_blended_el_b32l5.csv\n",
      "RUN: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3770 - mse: 0.3770 - mae: 0.4912\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3739 - mse: 0.3739 - mae: 0.4805\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3946 - mse: 0.3946 - mae: 0.4988\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3766 - mse: 0.3766 - mae: 0.4863\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3927 - mse: 0.3927 - mae: 0.4973\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3873 - mse: 0.3873 - mae: 0.4989\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4074 - mse: 0.4074 - mae: 0.5088\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4011 - mse: 0.4011 - mae: 0.5103\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3564 - mse: 0.3564 - mae: 0.4711\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3702 - mse: 0.3702 - mae: 0.4785\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b4e1000:         mse       mae        r2\n",
      "0  0.383714  0.492187  0.450186\n",
      "Saved CNN evaluation results for b4e1000 to: ../../data/evaluation_results/gan_blended_el_b4e1000.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3364 - mse: 0.3364 - mae: 0.4532\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3460 - mse: 0.3460 - mae: 0.4550\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3456 - mse: 0.3456 - mae: 0.4548\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3226 - mse: 0.3226 - mae: 0.4406\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3649 - mse: 0.3649 - mae: 0.4661\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2975 - mse: 0.2975 - mae: 0.4183\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3168 - mse: 0.3168 - mae: 0.4357\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3671 - mse: 0.3671 - mae: 0.4727\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3268 - mse: 0.3268 - mae: 0.4454\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3280 - mse: 0.3280 - mae: 0.4444\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b6e100:         mse       mae        r2\n",
      "0  0.335165  0.448621  0.519751\n",
      "Saved CNN evaluation results for b6e100 to: ../../data/evaluation_results/gan_blended_el_b6e100.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4323 - mse: 0.4323 - mae: 0.5265\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4398 - mse: 0.4398 - mae: 0.5287\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4231 - mse: 0.4231 - mae: 0.5184\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4547 - mse: 0.4547 - mae: 0.5393\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4521 - mse: 0.4521 - mae: 0.5448\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4535 - mse: 0.4535 - mae: 0.5415\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4444 - mse: 0.4444 - mae: 0.5356\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4336 - mse: 0.4336 - mae: 0.5276\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4369 - mse: 0.4369 - mae: 0.5257\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4385 - mse: 0.4385 - mae: 0.5309\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b8e500:         mse     mae        r2\n",
      "0  0.440889  0.5319  0.368262\n",
      "Saved CNN evaluation results for b8e500 to: ../../data/evaluation_results/gan_blended_el_b8e500.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4267 - mse: 0.4267 - mae: 0.5211\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4379 - mse: 0.4379 - mae: 0.5279\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4066 - mse: 0.4066 - mae: 0.5088\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4248 - mse: 0.4248 - mae: 0.5197\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4204 - mse: 0.4204 - mae: 0.5149\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3956 - mse: 0.3956 - mae: 0.4984\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4025 - mse: 0.4025 - mae: 0.5063\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4247 - mse: 0.4247 - mae: 0.5226\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3999 - mse: 0.3999 - mae: 0.5006\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4185 - mse: 0.4185 - mae: 0.5125\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b8e1000:         mse       mae        r2\n",
      "0  0.415755  0.513284  0.404276\n",
      "Saved CNN evaluation results for b8e1000 to: ../../data/evaluation_results/gan_blended_el_b8e1000.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3498 - mse: 0.3498 - mae: 0.4622\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3663 - mse: 0.3663 - mae: 0.4715\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3344 - mse: 0.3344 - mae: 0.4475\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3476 - mse: 0.3476 - mae: 0.4603\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3229 - mse: 0.3229 - mae: 0.4383\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3466 - mse: 0.3466 - mae: 0.4580\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3234 - mse: 0.3234 - mae: 0.4406\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3171 - mse: 0.3171 - mae: 0.4400\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2991 - mse: 0.2991 - mae: 0.4177\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3302 - mse: 0.3302 - mae: 0.4368\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b10e100:         mse       mae        r2\n",
      "0  0.333712  0.447303  0.521833\n",
      "Saved CNN evaluation results for b10e100 to: ../../data/evaluation_results/gan_blended_el_b10e100.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2979 - mse: 0.2979 - mae: 0.4181\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2935 - mse: 0.2935 - mae: 0.4131\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2502 - mse: 0.2502 - mae: 0.3867\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3294 - mse: 0.3294 - mae: 0.4453\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2577 - mse: 0.2577 - mae: 0.3785\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2808 - mse: 0.2808 - mae: 0.4078\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2778 - mse: 0.2778 - mae: 0.3964\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2813 - mse: 0.2813 - mae: 0.4047\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2893 - mse: 0.2893 - mae: 0.4065\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2858 - mse: 0.2858 - mae: 0.4081\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b12e100:         mse       mae        r2\n",
      "0  0.284387  0.406531  0.592509\n",
      "Saved CNN evaluation results for b12e100 to: ../../data/evaluation_results/gan_blended_el_b12e100.csv\n",
      "RUN: 0\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2874 - mse: 0.2874 - mae: 0.4110\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3440 - mse: 0.3440 - mae: 0.4487\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3492 - mse: 0.3492 - mae: 0.4608\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2904 - mse: 0.2904 - mae: 0.4022\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2995 - mse: 0.2995 - mae: 0.4208\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2937 - mse: 0.2937 - mae: 0.4159\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2822 - mse: 0.2822 - mae: 0.4067\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3486 - mse: 0.3486 - mae: 0.4529\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2834 - mse: 0.2834 - mae: 0.4112\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3168 - mse: 0.3168 - mae: 0.4239\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b12e500:         mse       mae        r2\n",
      "0  0.309521  0.425403  0.556495\n",
      "Saved CNN evaluation results for b12e500 to: ../../data/evaluation_results/gan_blended_el_b12e500.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4221 - mse: 0.4221 - mae: 0.5209\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3966 - mse: 0.3966 - mae: 0.5035\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4220 - mse: 0.4220 - mae: 0.5225\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3981 - mse: 0.3981 - mae: 0.5018\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4131 - mse: 0.4131 - mae: 0.5114\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4169 - mse: 0.4169 - mae: 0.5143\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3872 - mse: 0.3872 - mae: 0.4910\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3849 - mse: 0.3849 - mae: 0.4872\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3924 - mse: 0.3924 - mae: 0.4936\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3913 - mse: 0.3913 - mae: 0.4917\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b16e500:         mse       mae        r2\n",
      "0  0.402478  0.503786  0.423301\n",
      "Saved CNN evaluation results for b16e500 to: ../../data/evaluation_results/gan_blended_el_b16e500.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3295 - mse: 0.3295 - mae: 0.4473\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3589 - mse: 0.3589 - mae: 0.4702\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3214 - mse: 0.3214 - mae: 0.4402\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3397 - mse: 0.3397 - mae: 0.4548\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3299 - mse: 0.3299 - mae: 0.4424\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3215 - mse: 0.3215 - mae: 0.4397\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3611 - mse: 0.3611 - mae: 0.4759\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3001 - mse: 0.3001 - mae: 0.4287\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3222 - mse: 0.3222 - mae: 0.4390\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3125 - mse: 0.3125 - mae: 0.4361\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b20e500:        mse       mae       r2\n",
      "0  0.32968  0.447434  0.52761\n",
      "Saved CNN evaluation results for b20e500 to: ../../data/evaluation_results/gan_blended_el_b20e500.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3978 - mse: 0.3978 - mae: 0.5029\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3726 - mse: 0.3726 - mae: 0.4833\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3942 - mse: 0.3942 - mae: 0.4947\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3960 - mse: 0.3960 - mae: 0.4984\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3926 - mse: 0.3926 - mae: 0.4930\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4031 - mse: 0.4031 - mae: 0.5055\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3662 - mse: 0.3662 - mae: 0.4771\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3948 - mse: 0.3948 - mae: 0.4972\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3770 - mse: 0.3770 - mae: 0.4846\n",
      "4/4 [==============================] - 1s 3ms/step\n",
      "RUN: 9\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3916 - mse: 0.3916 - mae: 0.4956\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b24e1000:        mse       mae      r2\n",
      "0  0.38859  0.493221  0.4432\n",
      "Saved CNN evaluation results for b24e1000 to: ../../data/evaluation_results/gan_blended_el_b24e1000.csv\n",
      "RUN: 0\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4047 - mse: 0.4047 - mae: 0.5089\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4319 - mse: 0.4319 - mae: 0.5294\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4017 - mse: 0.4017 - mae: 0.5039\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3999 - mse: 0.3999 - mae: 0.5075\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4181 - mse: 0.4181 - mae: 0.5211\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4163 - mse: 0.4163 - mae: 0.5147\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 6\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4158 - mse: 0.4158 - mae: 0.5116\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3949 - mse: 0.3949 - mae: 0.5013\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4246 - mse: 0.4246 - mae: 0.5208\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4182 - mse: 0.4182 - mae: 0.5197\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "CNN results for b32e1000:         mse       mae        r2\n",
      "0  0.412594  0.513886  0.408805\n",
      "Saved CNN evaluation results for b32e1000 to: ../../data/evaluation_results/gan_blended_el_b32e1000.csv\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_save_cnn_blended(el_vae_data, 'vae', 1)\n",
    "evaluate_and_save_cnn_blended(el_gan_data, 'gan', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c44349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4935f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 15:43:18.429048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6876 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1\n",
      "2024-04-09 15:43:26.891783: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-04-09 15:43:37.315788: I external/local_xla/xla/service/service.cc:168] XLA service 0x2baff0e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-09 15:43:37.315831: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2024-04-09 15:43:37.421120: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712673817.784725    4520 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1545 - mse: 0.1545 - mae: 0.3069\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 1\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1649 - mse: 0.1649 - mae: 0.3164\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 2\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1494 - mse: 0.1494 - mae: 0.2944\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 3\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1483 - mse: 0.1483 - mae: 0.2932\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 4\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1436 - mse: 0.1436 - mae: 0.2881\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 5\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1481 - mse: 0.1481 - mae: 0.2903\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 6\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch: 89.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 99: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1583 - mse: 0.1583 - mae: 0.3069\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 7\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 98: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1519 - mse: 0.1519 - mae: 0.3028\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 8\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1550 - mse: 0.1550 - mae: 0.3044\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 9\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1522 - mse: 0.1522 - mae: 0.3010\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 10\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 58: early stopping\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1616 - mse: 0.1616 - mae: 0.3101\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 11\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1430 - mse: 0.1430 - mae: 0.2877\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 12\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1468 - mse: 0.1468 - mae: 0.2858\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 13\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1523 - mse: 0.1523 - mae: 0.2983\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 14\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1507 - mse: 0.1507 - mae: 0.3032\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 15\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1607 - mse: 0.1607 - mae: 0.3061\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 16\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1463 - mse: 0.1463 - mae: 0.2940\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 17\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1452 - mse: 0.1452 - mae: 0.2882\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 18\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1540 - mse: 0.1540 - mae: 0.3027\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 19\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1601 - mse: 0.1601 - mae: 0.3149\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 20\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1452 - mse: 0.1452 - mae: 0.2841\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 21\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1496 - mse: 0.1496 - mae: 0.2969\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 22\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1432 - mse: 0.1432 - mae: 0.2854\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "RUN: 23\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1529 - mse: 0.1529 - mae: 0.3045\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 24\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1445 - mse: 0.1445 - mae: 0.2877\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 25\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1523 - mse: 0.1523 - mae: 0.3025\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 26\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1529 - mse: 0.1529 - mae: 0.3026\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 27\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1520 - mse: 0.1520 - mae: 0.2965\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 28\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1464 - mse: 0.1464 - mae: 0.2896\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 29\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1557 - mse: 0.1557 - mae: 0.3064\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 30\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1632 - mse: 0.1632 - mae: 0.3173\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 31\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1561 - mse: 0.1561 - mae: 0.3065\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 32\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1551 - mse: 0.1551 - mae: 0.3022\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 33\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1593 - mse: 0.1593 - mae: 0.3042\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 34\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1577 - mse: 0.1577 - mae: 0.3071\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 35\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1503 - mse: 0.1503 - mae: 0.2996\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 36\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1458 - mse: 0.1458 - mae: 0.2961\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 37\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1653 - mse: 0.1653 - mae: 0.3198\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 38\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1502 - mse: 0.1502 - mae: 0.3005\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 39\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1555 - mse: 0.1555 - mae: 0.3056\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 40\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1526 - mse: 0.1526 - mae: 0.3025\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 41\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1593 - mse: 0.1593 - mae: 0.3094\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 42\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1450 - mse: 0.1450 - mae: 0.2915\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 43\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1533 - mse: 0.1533 - mae: 0.3030\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 44\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1455 - mse: 0.1455 - mae: 0.2888\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 45\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1523 - mse: 0.1523 - mae: 0.3012\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 46\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1514 - mse: 0.1514 - mae: 0.3024\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1546 - mse: 0.1546 - mae: 0.3050\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 48\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1623 - mse: 0.1623 - mae: 0.3126\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 49\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1523 - mse: 0.1523 - mae: 0.3044\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 50\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1559 - mse: 0.1559 - mae: 0.3074\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 51\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1412 - mse: 0.1412 - mae: 0.2735\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 52\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1590 - mse: 0.1590 - mae: 0.3107\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 53\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1454 - mse: 0.1454 - mae: 0.2871\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 54\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1541 - mse: 0.1541 - mae: 0.2981\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 55\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1437 - mse: 0.1437 - mae: 0.2890\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 56\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1584 - mse: 0.1584 - mae: 0.3092\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 57\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1477 - mse: 0.1477 - mae: 0.2943\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 58\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1546 - mse: 0.1546 - mae: 0.3029\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 59\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1533 - mse: 0.1533 - mae: 0.3011\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 60\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1369 - mse: 0.1369 - mae: 0.2712\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 61\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1501 - mse: 0.1501 - mae: 0.2957\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 62\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1490 - mse: 0.1490 - mae: 0.2973\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "RUN: 63\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_save_cnn(th_vae_data, 'vae', 0)\n",
    "evaluate_and_save_cnn(th_gan_data, 'gan', 0)\n",
    "\n",
    "evaluate_and_save_cnn_blended(th_vae_data, 'vae', 0)\n",
    "evaluate_and_save_cnn_blended(th_gan_data, 'gan', 0)\n",
    "\n",
    "evaluate_and_save_cnn(el_vae_data, 'vae', 1)\n",
    "evaluate_and_save_cnn(el_gan_data, 'gan', 1)\n",
    "\n",
    "evaluate_and_save_cnn_blended(el_vae_data, 'vae', 1)\n",
    "evaluate_and_save_cnn_blended(el_gan_data, 'gan', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52621053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a919799d-e034-4e82-8459-28975d0b2fba",
   "metadata": {},
   "source": [
    "<h2> Select and compare data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30a3d709-1516-4d53-970b-5048df5adff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def find_best_model(prefix):\n",
    "    folder_path = '../../data/evaluation_results/cnn/'\n",
    "\n",
    "    file_paths = glob.glob(f'{folder_path}{prefix}*.csv')\n",
    "    \n",
    "    mse_vals = {}\n",
    "    best_val, best_df, best_name = float('inf'), None, ''\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        mse_val = df['mse'].iloc[0]\n",
    "        mse_vals[file_path] = mse_val\n",
    "        \n",
    "        if mse_val < best_val:\n",
    "            best_val, best_df = mse_val, df\n",
    "            best_name = file_path.split('/')[-1]\n",
    "\n",
    "    sorted_mse_vals = sorted(mse_vals.items(), key=lambda item: item[1])\n",
    "    \n",
    "    for name, value in sorted_mse_vals:\n",
    "        print(name.split('/')[-1], value)\n",
    "        \n",
    "    print(f'\\nDataFrame with lowest MSE ({best_name}):\\n{best_df}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c952fd1-f985-4683-b84c-f1b3cda8b909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Thermal\n",
      "cnn\\vae_th_b20l3.csv 0.1190055929124355\n",
      "cnn\\vae_th_b8l15.csv 0.1265775240957737\n",
      "cnn\\vae_th_b16l5.csv 0.1314404964447021\n",
      "cnn\\vae_th_b4l5.csv 0.1364974901080131\n",
      "cnn\\vae_th_b20l5.csv 0.1520956456661224\n",
      "cnn\\vae_th_b24l15.csv 0.1523252636194229\n",
      "cnn\\vae_th_b4l10.csv 0.1532680049538612\n",
      "cnn\\vae_th_b24l50.csv 0.1778552532196045\n",
      "cnn\\vae_th_b16l10.csv 0.1802604213356971\n",
      "cnn\\vae_th_b8l20.csv 0.5562011629343033\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\vae_th_b20l3.csv):\n",
      "   Unnamed: 0    mse     mae      r2\n",
      "0           0  0.119  0.2626  0.3321\n",
      "\n",
      "cnn\\gan_th_b8e1000.csv 0.2068981036543846\n",
      "cnn\\gan_th_b32e100.csv 0.2844437450170517\n",
      "cnn\\gan_th_b8e500.csv 0.2867301911115646\n",
      "cnn\\gan_th_b20e100.csv 0.3444884002208709\n",
      "cnn\\gan_th_b6e100.csv 0.4662655055522918\n",
      "cnn\\gan_th_b32e500.csv 0.5470245212316514\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\gan_th_b8e1000.csv):\n",
      "   Unnamed: 0     mse     mae      r2\n",
      "0           0  0.2069  0.3807 -0.1612\n",
      "\n",
      "\n",
      "Context: Electrical\n",
      "cnn\\vae_el_b8l10.csv 0.4488880276679993\n",
      "cnn\\vae_el_b24l3.csv 0.460650372505188\n",
      "cnn\\vae_el_b32l3.csv 0.4674365490674972\n",
      "cnn\\vae_el_b20l3.csv 0.4794443905353546\n",
      "cnn\\vae_el_b32l5.csv 0.4821873813867569\n",
      "cnn\\vae_el_b4l3.csv 0.5005753338336945\n",
      "cnn\\vae_el_b20l20.csv 0.535299152135849\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\vae_el_b8l10.csv):\n",
      "   Unnamed: 0     mse     mae      r2\n",
      "0           0  0.4489  0.5438  0.3568\n",
      "\n",
      "cnn\\gan_el_b20e500.csv 0.6525217473506928\n",
      "cnn\\gan_el_b24e1000.csv 0.6589860200881958\n",
      "cnn\\gan_el_b4e1000.csv 0.6608556270599365\n",
      "cnn\\gan_el_b10e100.csv 0.6903378903865814\n",
      "cnn\\gan_el_b32e1000.csv 0.7058127760887146\n",
      "cnn\\gan_el_b16e500.csv 0.7213095486164093\n",
      "cnn\\gan_el_b8e1000.csv 0.7526354789733887\n",
      "cnn\\gan_el_b12e100.csv 0.7568051278591156\n",
      "cnn\\gan_el_b8e500.csv 0.7750153601169586\n",
      "cnn\\gan_el_b6e100.csv 0.7756770730018616\n",
      "cnn\\gan_el_b12e500.csv 1.2655772984027862\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\gan_el_b20e500.csv):\n",
      "   Unnamed: 0     mse     mae     r2\n",
      "0           0  0.6525  0.7187  0.065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Context: Thermal')\n",
    "find_best_model('vae_th')\n",
    "find_best_model('gan_th')\n",
    "\n",
    "print('\\nContext: Electrical')\n",
    "find_best_model('vae_el')\n",
    "find_best_model('gan_el')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88edc2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Thermal\n",
      "cnn\\vae_blended_th_b20l3.csv 0.0781151488423347\n",
      "cnn\\vae_blended_th_b4l10.csv 0.0924433469772338\n",
      "cnn\\vae_blended_th_b8l15.csv 0.0932417020201683\n",
      "cnn\\vae_blended_th_b4l5.csv 0.0968162976205349\n",
      "cnn\\vae_blended_th_b24l15.csv 0.09766411408782\n",
      "cnn\\vae_blended_th_b16l5.csv 0.1016411677002906\n",
      "cnn\\vae_blended_th_b20l5.csv 0.1065429620444774\n",
      "cnn\\vae_blended_th_b24l50.csv 0.1090219363570213\n",
      "cnn\\vae_blended_th_b16l10.csv 0.120886443555355\n",
      "cnn\\vae_blended_th_b8l20.csv 0.1320243626832962\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\vae_blended_th_b20l3.csv):\n",
      "   Unnamed: 0     mse     mae      r2\n",
      "0           0  0.0781  0.2037  0.5616\n",
      "\n",
      "cnn\\gan_blended_th_b20e100.csv 0.0895717576146125\n",
      "cnn\\gan_blended_th_b32e500.csv 0.1010843776166439\n",
      "cnn\\gan_blended_th_b8e1000.csv 0.1029256179928779\n",
      "cnn\\gan_blended_th_b32e100.csv 0.1281974203884601\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\gan_blended_th_b20e100.csv):\n",
      "   Unnamed: 0     mse     mae      r2\n",
      "0           0  0.0896  0.2154  0.4973\n",
      "\n",
      "\n",
      "Context: Electrical\n",
      "cnn\\vae_blended_el_b20l3.csv 0.2535918995738029\n",
      "cnn\\vae_blended_el_b24l3.csv 0.2749372079968452\n",
      "cnn\\vae_blended_el_b32l3.csv 0.2798540830612183\n",
      "cnn\\vae_blended_el_b32l5.csv 0.2960797667503357\n",
      "cnn\\vae_blended_el_b8l10.csv 0.2969275802373886\n",
      "cnn\\vae_blended_el_b4l3.csv 0.301945886015892\n",
      "cnn\\vae_blended_el_b20l20.csv 0.3226022779941558\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\vae_blended_el_b20l3.csv):\n",
      "   Unnamed: 0     mse     mae      r2\n",
      "0           0  0.2536  0.3789  0.6366\n",
      "\n",
      "cnn\\gan_blended_el_b12e100.csv 0.2843874543905258\n",
      "cnn\\gan_blended_el_b12e500.csv 0.3095213562250137\n",
      "cnn\\gan_blended_el_b20e500.csv 0.329680386185646\n",
      "cnn\\gan_blended_el_b10e100.csv 0.333711576461792\n",
      "cnn\\gan_blended_el_b6e100.csv 0.3351649463176727\n",
      "cnn\\gan_blended_el_b4e1000.csv 0.3837144494056702\n",
      "cnn\\gan_blended_el_b24e1000.csv 0.3885896325111389\n",
      "cnn\\gan_blended_el_b16e500.csv 0.4024775505065918\n",
      "cnn\\gan_blended_el_b32e1000.csv 0.4125942677259445\n",
      "cnn\\gan_blended_el_b8e1000.csv 0.4157545506954193\n",
      "cnn\\gan_blended_el_b8e500.csv 0.4408891141414642\n",
      "\n",
      "DataFrame with lowest MSE (cnn\\gan_blended_el_b12e100.csv):\n",
      "   Unnamed: 0     mse     mae      r2\n",
      "0           0  0.2844  0.4065  0.5925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Context: Thermal')\n",
    "find_best_model('vae_blended_th')\n",
    "find_best_model('gan_blended_th')\n",
    "\n",
    "print('\\nContext: Electrical')\n",
    "find_best_model('vae_blended_el')\n",
    "find_best_model('gan_blended_el')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce785e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
